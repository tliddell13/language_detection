{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d67b4a",
   "metadata": {},
   "source": [
    "# Language Detection Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82feb43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import joblib\n",
    "import unicodedata\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83982a",
   "metadata": {},
   "source": [
    "## Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0  Klement Gottwaldi surnukeha palsameeriti ning ...   est\n",
      "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....   swe\n",
      "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...   mai\n",
      "3  Après lo cort periòde d'establiment a Basilèa,...   oci\n",
      "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...   tha\n",
      "                                                text label\n",
      "0  klementgottwaldisurnukehapalsameeritiningpaigu...   est\n",
      "1  sebesjosephpereirathomaspåengthejesuitsandthes...   swe\n",
      "2  भरतयसवतनतरयआनदलनरषटरयएवमकषतरयआहवनउततजनसभएवमपरय...   mai\n",
      "3  aprèslocortperiòdedestablimentabasilèatornètav...   oci\n",
      "4  ถนนเจรญกรงอกษรโรมนthanoncharoenkrungเรมตงแตถนน...   tha\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "I decided to use the Wikipedia Language Identification Benchmark dataset to train my model. \n",
    "The dataset can be found at\n",
    "https://www.kaggle.com/datasets/mexwell/wili-2018?resource=download\n",
    "It is composed of 235 languages, with 1000 samples per language, equaling 235,000 total samples.\n",
    "\"\"\"\n",
    "\n",
    "# Read the text file of data by each line into a list\n",
    "with open('wiki_languages/x_train.txt', 'r', encoding='utf-8') as file:\n",
    "    data = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "data = pd.DataFrame(data, columns=['text'])\n",
    "\n",
    "# Read the text file of labels by each line into a list\n",
    "with open('wiki_languages/y_train.txt', 'r', encoding='utf-8') as file:\n",
    "    labels = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Convert the labels list to a series\n",
    "labels = pd.Series(labels, name='label')\n",
    "\n",
    "# Combine the data and labels into a single DataFrame\n",
    "data['label'] = labels\n",
    "\n",
    "# lets take a look at what the first few rows of the dataset look like\n",
    "print(data.head())\n",
    "\n",
    "# Normalize text. \n",
    "def normalize_text(text):\n",
    "    # Remove URL patterns, email addresses\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove numbers (language-agnostic)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Keep only Unicode letters (removes spaces, punctuation, etc.)\n",
    "    text = ''.join(char for char in text if unicodedata.category(char).startswith('L'))\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "data_char = data.copy()\n",
    "data_char['text'] = data_char['text'].apply(normalize_text)\n",
    "\n",
    "print(data_char.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3370c4",
   "metadata": {},
   "source": [
    "## N - Gram -> TF-IDF -> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7175897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (94000, 10000)\n",
      "Testing data shape: (23500, 10000)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "First I decided to implement a pipeline that uses:\n",
    "N - Grams -> TF-IDF -> Multinomial Naive Bayes\n",
    "N-Grams were used for text categorization in the paper\n",
    "\"N-Gram-Based Text Categorization\" by Cavnar and Trenkle (1994). \n",
    "Found here: https://dsacl3-2019.github.io/materials/CavnarTrenkle.pdf\n",
    "\"\"\"    \n",
    "\n",
    "# Split the data into training and testing sets (The actual test set will be used later to compare both models)\n",
    "# 80 - 20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_char['text'], data_char['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Make a copy of the test so I can look at the actual text later\n",
    "X_test_copy = X_test.copy()\n",
    "\"\"\"\n",
    "TF-IDF is an excellent choice for language classification because it is able to capture the importance of words (or n-grams) in a sentence relative to a collection of documents (corpus).\n",
    "\n",
    "Setting the n-gram range had the most impact on the accuracy of the model.\n",
    "The other parameters had little effect on the accuracy.\n",
    "Without setting the max features, there are over 1 million features, but the model performs similarly with 10,000 features.\n",
    "\"\"\"\n",
    "# Create the TF-IDF Vectorizer with N-Grams \n",
    "# Experimenting with different n-gram ranges\n",
    "# 92 percent accuracy with (1,3)\n",
    "# 92 percent accuracy with (1,4) as well, but takes longer to train\n",
    "# 90 percent accuracy with (2,2)\n",
    "# 91 percent accuracy with (3,3)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char', max_features=10000)\n",
    "\n",
    "# Fit and transform the training data, then transform the test data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(f'Training data shape: {X_train_tfidf.shape}')\n",
    "print(f'Testing data shape: {X_test_tfidf.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694344f",
   "metadata": {},
   "source": [
    "## Top 20 n-grams from TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9381d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 16669.83824761838), ('e', 13341.703706330049), ('i', 11582.40107432654), ('n', 11087.403273121598), ('o', 8056.091283492217), ('r', 7982.703426418032), ('s', 7725.368596663948), ('t', 7650.225450853047), ('l', 6431.788076277917), ('u', 5857.664059633923), ('d', 5659.075196264574), ('m', 4582.983435780269), ('k', 4364.926345934529), ('а', 4335.96190857824), ('g', 3735.818590706789), ('h', 3701.426142844057), ('c', 3641.9514976263245), ('p', 3215.984674807888), ('an', 3083.579728266576), ('b', 2751.966374241374)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at what the TF-IDF gave us:\n",
    "# Lets take a look at some of the most distinctive (TF-IDF score) n-grams across the entire training set\n",
    "sum_words = X_train_tfidf.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "common_words = words_freq[:20]  \n",
    "print(common_words)\n",
    "df_common_words = pd.DataFrame(common_words, columns=['N-Gram', 'TF-IDF Score'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TF-IDF Score', y='N-Gram', data=df_common_words)\n",
    "plt.title('Top 20 N-Grams by TF-IDF Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c1ae4",
   "metadata": {},
   "source": [
    "## Train Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9108\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multinomial Naive Bayes is a good choice for text classification tasks, especially when dealing with discrete features like word counts or frequencies.\n",
    "It also works well with the TF-IDF representation of text data.\n",
    "\"\"\"\n",
    "# Now I will train a Multinomial Naive Bayes model on the TF-IDF transformed data\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train_tfidf, y_train)\n",
    "y_pred = naive_bayes_model.predict(X_test_tfidf)\n",
    "\n",
    "#print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a7f1a",
   "metadata": {},
   "source": [
    "## Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef3583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: Konkani (kok) - Predicted: Marathi (mar)\n",
      "Text Sample: गवतशसकयपरवपरथमकशळआसगवतशसकयपरथमकशळआसगवतशसकयकनषठमधयमकशळआसगवतशसकयमधयमकशळआससगळयतलगउचचमधयमकशळbaliकलमटरपरसचडअतरचरआससगळयतलगपदवमहवदयलयcuncolimतकलमटरचयअतरचरआससगळयतलगअभयतरकमहवदयलयbandoractकलमटरपरसचडअतरचरआससगळयतलगवजकमहवदयलयbambolimctकलमटरपरसचडअतरचरआससगळयतलगववसथपनससथmargaoकलमटरपरसचडअतरचरआससगळयतलगपलटकनकcurchoremcacoraकलमटरपरसचडअतरचरआससगळयतलगववसयकपरशकषणशळcanaconaकलमटरपरसचडअतरचरआससगळयतलगअनपचरकपरशकषणकदरmargaoकलमटरपरसचडअतरचरआससगळयतलगअपगखतरखशलशळmargaoकलमटरपरसचडअतरचरआस\n",
      "\n",
      "\n",
      "True: Pangasinan (pag) - Predicted: Tagalog (tgl)\n",
      "Text Sample: nikristofferryanagoncilloinianakabriledlungsodngmaynilasakeyarapanyabatikandiadpilipinoranpunongabalaedtelebisiontanartistasoyasawanenjudyannsantostannagsisilbiedpunongabalana\n",
      "\n",
      "\n",
      "True: Belarusian (bel) - Predicted: Belarusian (Taraschkewiza) (be-tarask)\n",
      "Text Sample: укаледжавельміпаважнаярэпутацыямногіячленыбрытанскайкаралеўскайсямізяўлялісяяговыпускнікамікарольэдуардviiкарольгеоргviпрынцгенрыгерцагглостэрскіічарльзпрынцуэльскі\n",
      "\n",
      "\n",
      "True: Erzya (myv) - Predicted: Russian (rus)\n",
      "Text Sample: специфическиепринципыизучениясловообразованияввузенаматериалемордовскихязыковнаучныеизданиямосковскоговенгерскогоколледжамвалангчс\n",
      "\n",
      "\n",
      "True: Crimean Tatar (crh) - Predicted: Turkish (tur)\n",
      "Text Sample: senesimüellifniñkündoğdıadlıromanıdünyayüzünikördii̇smailgasprinskiyniñerekiromanıvedigerbediiyparçalarıtürkveumumenmusulmandünyasınıñsiyasiyvebediiyfikiriniñşekilledirmesindebüyükroloynadılar\n",
      "\n",
      "\n",
      "True: Gilaki (glk) - Predicted: Persian (fas)\n",
      "Text Sample: تاریخچهاپرندهیاولیندفاایتهزیستشناسکیاونینامسرجانگلدبومیلادیببردهبهانگلستانبعدانیموتقاضیزیادهبوستوکشتیانهزیادیدستبهکارانتقالاپرندهیانبوبوستیدیکیاشنهویشتربردیدیاروپابخصوصانگلستانهلندبلژیکاشنهاوموقادردستههایچنددههیزارتاییحملکودیدیودرطولاوسفرچندهفتهایفقطتعدادکمیازاشنسالمفارسائیداروپابهزودیاپرندهاهلیبوبوستوازطریقانگلستانانهبهتومامدونیااوسیکودد\n",
      "\n",
      "\n",
      "True: Egyptian Arabic (arz) - Predicted: Arabic (ara)\n",
      "Text Sample: مسجدومقبرةمحمدالمحروقمنمساجدالتيموريةالصفويةاسسعاموفیهقبرمحمدالمحروقویزارعندشيعةوفیهأیضااثرامامالثامنشيعةعليبنموسیالرضاعلیحجراسودویعتبرهذاالمسجدمنآياتفنالإيرانيةالصفويةومسجلفىمنظمةالتراثالثقافيفىإیرانکتيبتينموجودفیهمنناصرالدينشاهقاجاروشاهطهماسبالصفوي\n",
      "\n",
      "\n",
      "True: Marathi (mar) - Predicted: English (eng)\n",
      "Text Sample: theeconomicpositionofwidowshasbeenanimportantsocialissueinmanysocietiesinsocietiesinwhichthehusbandwastypicallythesoleproviderhisdeathcouldplungehisfamilyintopovertythiswasaggravatedbywomenslongerlifespansandthatmengenerallymarrywomenyoungerthanthemselvesmanycharitiesexistedtohelpwidowsandorphansoftennotchildrenwithoutparentsbutchildrenwithoutacontributingfatherinneed\n",
      "\n",
      "\n",
      "True: Classical Nahuatl (nci) - Predicted: Spanish (spa)\n",
      "Text Sample: yanoeditaréconmacronesesocomplicalaescrituraesmuytediosorevizarlosdiccionariosparaverdondeestálaprolongacióndelavocalyademásnoexisteunareglageneralizadaempezaréaeditarlosartículosconescrituralatinasinmacronescomolohacenmuchaspersonasensulenguamaternaesvalidohacerloporqueelisoesnahynoncijosémegustanmuchotuspropuestasdeneologismosperonohaycertezadetalaceptaciónenusuariosnativos\n",
      "\n",
      "\n",
      "True: Western Panjabi (pnb) - Predicted: Persian (fas)\n",
      "Text Sample: درسالقمریعضدالدولهدیلمیواردبغدادشدسپسبهزیارتکربلاونجفشتافتودستوردادمرقدعظیموباشکوهیبرایعباسبنعلیبناکنندبنایمزبوردرسالقمریآغازشدودرسالپایانیافتوعمارتامروزهحرمعباسبنعلیازعضدالدولهاستکهازشکوهوعظمتخاصیبرخورداراست\n",
      "\n",
      "\n",
      "Most common confusions:\n",
      "Chavacano -> Spanish: 59\n",
      "Gilaki -> Persian: 52\n",
      "Konkani -> Marathi: 50\n",
      "Nepali (macrolanguage) -> Doteli: 43\n",
      "Classical Nahuatl -> Spanish: 31\n",
      "Rusyn -> Russian: 27\n",
      "Erzya -> Russian: 26\n",
      "Serbo-Croatian -> Croatian: 24\n",
      "Picard -> French: 24\n",
      "Pampanga -> German: 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe common confusions are languages that are very similar to each other as expected.\\nAfter looking at some of the mistakes I noticed that it is because some of the samples contain multiple languages in one sample. This may make the model more \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the labels csv to get the language names\n",
    "labels_df = pd.read_csv('wiki_languages/labels.csv', sep=';')\n",
    "# Create a mapping from label to language name\n",
    "label_map = dict(zip(labels_df['Label'], labels_df['English']))\n",
    "\n",
    "# Make a list of all the mistakes, with predicted and actual language names\n",
    "mistakes = []\n",
    "for i, (true_label, pred_label) in enumerate(zip(y_test, y_pred)):\n",
    "    if true_label != pred_label:\n",
    "        mistakes.append({\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': pred_label,\n",
    "            'true_language': label_map.get(true_label, true_label),\n",
    "            'predicted_language': label_map.get(pred_label, pred_label),\n",
    "            # The original text sample that was misclassified\n",
    "            'text_sample': X_test_copy.iloc[i]  \n",
    "        })\n",
    "\n",
    "# Print the first 10 mistakes mistakes\n",
    "for mistake in mistakes[:10]:  \n",
    "    print(f\"True: {mistake['true_language']} ({mistake['true_label']}) - Predicted: {mistake['predicted_language']} ({mistake['predicted_label']})\")\n",
    "    print(f\"Text Sample: {mistake['text_sample']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# What languages were most commonly confused?\n",
    "confusion_counts = {}\n",
    "for mistake in mistakes:\n",
    "    pair = (mistake['true_language'], mistake['predicted_language'])\n",
    "    if pair not in confusion_counts:\n",
    "        confusion_counts[pair] = 0\n",
    "    confusion_counts[pair] += 1\n",
    "\n",
    "# Sort by most common confusions\n",
    "sorted_confusions = sorted(confusion_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Most common confusions:\")\n",
    "# 10 most common confused languages\n",
    "for (true_lang, pred_lang), count in sorted_confusions[:10]:  \n",
    "    print(f\"{true_lang} -> {pred_lang}: {count}\")\n",
    "\n",
    "\"\"\"\n",
    "The common confusions are languages that are very similar to each other as expected.\n",
    "After looking at some of the mistakes I noticed that it is because some of the samples contain multiple languages in one sample. \n",
    "\n",
    "If working on this project for longer I would go over this data more, as it could potentially help me improve the model's performance.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a949e73",
   "metadata": {},
   "source": [
    "## Word N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81b3dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word N-Gram Model Accuracy: 0.8834\n"
     ]
    }
   ],
   "source": [
    "# After exporting the above model and vectorizer to my command line script, I quickly found with some tests, that the model had overfit to the training data and struggled with short text and language with a more natural tone\n",
    "\n",
    "# To try and solve this, I tried using word n-grams rather than character\n",
    "# Same text as before, but cant remove the white space in between words obviously\n",
    "def normalize_text_word(text):\n",
    "    # Remove URLs, emails, numbers\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Clean up whitespace but preserve word boundaries\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  \n",
    "    return text.strip().lower()\n",
    "\n",
    "data_word = data.copy()\n",
    "data_word['text'] = data_word['text'].apply(normalize_text_word)\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', max_features=10000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_word['text'], data_word['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_word_tfidf = word_vectorizer.fit_transform(X_train)\n",
    "X_test_word_tfidf = word_vectorizer.transform(X_test)\n",
    "\n",
    "naive_bayes_model_word = MultinomialNB()\n",
    "naive_bayes_model_word.fit(X_train_word_tfidf, y_train)\n",
    "y_pred_word = naive_bayes_model_word.predict(X_test_word_tfidf)\n",
    "accuracy_word = accuracy_score(y_test, y_pred_word)\n",
    "print(f'Word N-Gram Model Accuracy: {accuracy_word:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816cf7ef",
   "metadata": {},
   "source": [
    "## Train on extra data for common languages (oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd1199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Model Accuracy: 0.7602\n",
      "Calibration model trained on oversampled NB outputs\n"
     ]
    }
   ],
   "source": [
    "# In real world scenarios, many of the languges in the dataset are very unlikely to occur. Below I will add some extra data for the most common languages to help the model generalize better.\n",
    "\n",
    "# The 10 most common languages\n",
    "common_languages = [\n",
    "    'zho',  # Mandarin Chinese\n",
    "    'hin',  # Hindi\n",
    "    'eng',  # English\n",
    "    'spa',  # Spanish\n",
    "    'ara',  # Arabic\n",
    "    'ben',  # Bengali\n",
    "    'por',  # Portuguese\n",
    "    'rus',  # Russian\n",
    "    'jpn',  # Japanese\n",
    "    'fra',  # French\n",
    "    'deu'   # German\n",
    "]\n",
    "\n",
    "# Oversample these languages by multiplying their samples in the training set\n",
    "common_lang_data = data[data['label'].isin(common_languages)]\n",
    "common_lang_data = pd.concat([common_lang_data]*2, ignore_index=True) \n",
    "\n",
    "# Combine with the original training data\n",
    "oversampled_train_data = pd.concat([data, common_lang_data], ignore_index=True)\n",
    "\n",
    "# Character preprocessing\n",
    "oversampled_train_data['text'] = oversampled_train_data['text'].apply(normalize_text)\n",
    "\n",
    "over_X_train, over_y_train = oversampled_train_data['text'], oversampled_train_data['label']\n",
    "over_vectorizer = TfidfVectorizer(ngram_range=(2, 3), analyzer='char', max_features=10000)\n",
    "over_X_train_tfidf = over_vectorizer.fit_transform(over_X_train)\n",
    "X_test_tfidf = over_vectorizer.transform(X_test)\n",
    "naive_bayes_model_over = MultinomialNB()\n",
    "naive_bayes_model_over.fit(over_X_train_tfidf, over_y_train)\n",
    "y_pred_over = naive_bayes_model_over.predict(X_test_tfidf)\n",
    "accuracy_over = accuracy_score(y_test, y_pred_over)\n",
    "print(f'Oversampled Model Accuracy: {accuracy_over:.4f}')\n",
    "\n",
    "# Accuracy dropped signigicantly, but it gets the short common phrases correct that the previous model missed.\n",
    "# Below I will create an ensemble model that uses both models and picks the prediction from the model that is more confident in its prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f951e",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe by combining the oversampling method and the original model, I can keep some performance on the dataset while also helping with the generalization issue\n",
    "def ensemble_predict(text):\n",
    "    text_char = normalize_text(text)\n",
    "    \n",
    "    orig_features = vectorizer.transform([text_char])\n",
    "    orig_proba = naive_bayes_model.predict_proba(orig_features)[0]\n",
    "    \n",
    "    over_features = over_vectorizer.transform([text_char])\n",
    "    over_proba = naive_bayes_model_over.predict_proba(over_features)[0]\n",
    "    \n",
    "    # Weighted average (favor oversampled for common languages)\n",
    "    combined_proba = 0.3 * orig_proba + 0.7 * over_proba\n",
    "    final_pred = naive_bayes_model.classes_[combined_proba.argmax()]\n",
    "    final_confidence = combined_proba.max()\n",
    "\n",
    "    return final_pred, final_confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72427048",
   "metadata": {},
   "source": [
    "## Generalization test (Random simple conversational type sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Results:\n",
      "'Hello, how are you today?' -> English Ensemble model, conf: 0.450)\n",
      "'What's the weather like?' -> English Ensemble model, conf: 0.707)\n",
      "'Thank you very much' -> English Ensemble model, conf: 0.125)\n",
      "'Nice to meet you' -> English Ensemble model, conf: 0.268)\n",
      "'Have a great day' -> English Ensemble model, conf: 0.189)\n",
      "'How was your weekend?' -> English Ensemble model, conf: 0.189)\n",
      "'I'm doing well, thanks' -> English Ensemble model, conf: 0.125)\n",
      "'See you later' -> English Ensemble model, conf: 0.189)\n",
      "'Good morning everyone' -> English Ensemble model, conf: 0.572)\n",
      "'Can you help me please?' -> English Ensemble model, conf: 0.308)\n",
      "'I love this song' -> English Ensemble model, conf: 0.524)\n",
      "'What time is it?' -> English Ensemble model, conf: 0.343)\n",
      "'Where are you from?' -> English Ensemble model, conf: 0.667)\n",
      "'How much does this cost?' -> English Ensemble model, conf: 0.343)\n",
      "'I'm hungry, let's eat' -> English Ensemble model, conf: 0.125)\n",
      "'Excuse me' -> French Ensemble model, conf: 0.125)\n",
      "'You're welcome' -> English Ensemble model, conf: 0.353)\n",
      "'I don't understand' -> German Ensemble model, conf: 0.296)\n",
      "'Could you repeat that?' -> English Ensemble model, conf: 0.696)\n",
      "'What's your name?' -> English Ensemble model, conf: 0.450)\n",
      "'Hola, ¿cómo estás?' -> Spanish Ensemble model, conf: 0.353)\n",
      "'¿Qué tal el tiempo?' -> French Ensemble model, conf: 0.419)\n",
      "'Muchas gracias' -> Spanish Ensemble model, conf: 0.308)\n",
      "'Mucho gusto' -> Scottish Gaelic Ensemble model, conf: 0.000)\n",
      "'Que tengas buen día' -> Spanish Ensemble model, conf: 0.268)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Spanish Ensemble model, conf: 0.308)\n",
      "'Estoy bien, gracias' -> Spanish Ensemble model, conf: 0.572)\n",
      "'Hasta luego' -> Spanish Ensemble model, conf: 0.189)\n",
      "'Buenos días a todos' -> Spanish Ensemble model, conf: 0.593)\n",
      "'¿Me puedes ayudar?' -> Spanish Ensemble model, conf: 0.343)\n",
      "'Me encanta esta canción' -> Spanish Ensemble model, conf: 0.627)\n",
      "'¿Qué hora es?' -> Spanish Ensemble model, conf: 0.189)\n",
      "'¿De dónde eres?' -> Spanish Ensemble model, conf: 0.450)\n",
      "'¿Cuánto cuesta esto?' -> Spanish Ensemble model, conf: 0.572)\n",
      "'Tengo hambre, vamos a comer' -> Portuguese Ensemble model, conf: 0.450)\n",
      "'Disculpe' -> Friulian Ensemble model, conf: 0.125)\n",
      "'De nada' -> Spanish Ensemble model, conf: 0.125)\n",
      "'No entiendo' -> Spanish Ensemble model, conf: 0.419)\n",
      "'¿Puedes repetir eso?' -> French Ensemble model, conf: 0.524)\n",
      "'¿Cómo te llamas?' -> Spanish Ensemble model, conf: 0.189)\n",
      "'Bonjour, comment allez-vous?' -> French Ensemble model, conf: 0.593)\n",
      "'Quel temps fait-il?' -> French Ensemble model, conf: 0.419)\n",
      "'Merci beaucoup' -> French Ensemble model, conf: 0.450)\n",
      "'Enchanté' -> French Ensemble model, conf: 0.268)\n",
      "'Passez une bonne journée' -> French Ensemble model, conf: 0.545)\n",
      "'Comment s'est passé votre weekend?' -> French Ensemble model, conf: 0.343)\n",
      "'Je vais bien, merci' -> French Ensemble model, conf: 0.000)\n",
      "'À bientôt' -> French Ensemble model, conf: 0.000)\n",
      "'Bonjour tout le monde' -> French Ensemble model, conf: 0.594)\n",
      "'Pouvez-vous m'aider?' -> French Ensemble model, conf: 0.308)\n",
      "'J'adore cette chanson' -> French Ensemble model, conf: 0.189)\n",
      "'Quelle heure est-il?' -> French Ensemble model, conf: 0.627)\n",
      "'D'où venez-vous?' -> Breton Ensemble model, conf: 0.533)\n",
      "'Combien ça coûte?' -> Portuguese Ensemble model, conf: 0.271)\n",
      "'J'ai faim, allons manger' -> English Ensemble model, conf: 0.000)\n",
      "'Excusez-moi' -> Lojban Ensemble model, conf: 0.524)\n",
      "'De rien' -> German Ensemble model, conf: 0.343)\n",
      "'Je ne comprends pas' -> French Ensemble model, conf: 0.268)\n",
      "'Pouvez-vous répéter?' -> French Ensemble model, conf: 0.593)\n",
      "'Comment vous appelez-vous?' -> French Ensemble model, conf: 0.308)\n",
      "'Hallo, wie geht es dir?' -> German Ensemble model, conf: 0.593)\n",
      "'Wie ist das Wetter?' -> German Ensemble model, conf: 0.593)\n",
      "'Vielen Dank' -> German Ensemble model, conf: 0.189)\n",
      "'Freut mich' -> German Ensemble model, conf: 0.343)\n",
      "'Schönen Tag noch' -> German Ensemble model, conf: 0.308)\n",
      "'Wie war dein Wochenende?' -> German Ensemble model, conf: 0.696)\n",
      "'Mir geht es gut, danke' -> German Ensemble model, conf: 0.343)\n",
      "'Bis später' -> German Ensemble model, conf: 0.343)\n",
      "'Guten Morgen alle' -> German Ensemble model, conf: 0.343)\n",
      "'Kannst du mir helfen?' -> German Ensemble model, conf: 0.308)\n",
      "'Ich liebe dieses Lied' -> German Ensemble model, conf: 0.627)\n",
      "'Wie spät ist es?' -> German Ensemble model, conf: 0.533)\n",
      "'Woher kommst du?' -> German Ensemble model, conf: 0.343)\n",
      "'Wie viel kostet das?' -> German Ensemble model, conf: 0.268)\n",
      "'Ich habe Hunger, lass uns essen' -> German Ensemble model, conf: 0.593)\n",
      "'Entschuldigung' -> German Ensemble model, conf: 0.572)\n",
      "'Bitte schön' -> German Ensemble model, conf: 0.343)\n",
      "'Ich verstehe nicht' -> German Ensemble model, conf: 0.707)\n",
      "'Können Sie das wiederholen?' -> German Ensemble model, conf: 0.593)\n",
      "'Wie heißen Sie?' -> German Ensemble model, conf: 0.627)\n",
      "'Привет, как дела?' -> Russian Ensemble model, conf: 0.593)\n",
      "'Какая погода?' -> Russian Ensemble model, conf: 0.707)\n",
      "'Большое спасибо' -> Russian Ensemble model, conf: 0.593)\n",
      "'Приятно познакомиться' -> Russian Ensemble model, conf: 0.707)\n",
      "'Хорошего дня' -> Russian Ensemble model, conf: 0.707)\n",
      "'Как прошли выходные?' -> Russian Ensemble model, conf: 0.707)\n",
      "'У меня всё хорошо, спасибо' -> Russian Ensemble model, conf: 0.593)\n",
      "'Увидимся позже' -> Russian Ensemble model, conf: 0.593)\n",
      "'Доброе утро всем' -> Russian Ensemble model, conf: 0.707)\n",
      "'Можете мне помочь?' -> Russian Ensemble model, conf: 0.707)\n",
      "'Мне нравится эта песня' -> Russian Ensemble model, conf: 0.627)\n",
      "'Который час?' -> Russian Ensemble model, conf: 0.696)\n",
      "'Откуда вы?' -> Russian Ensemble model, conf: 0.353)\n",
      "'Сколько это стоит?' -> Russian Ensemble model, conf: 0.707)\n",
      "'Я голоден, давайте поедим' -> Russian Ensemble model, conf: 0.593)\n",
      "'Извините' -> Russian Ensemble model, conf: 0.450)\n",
      "'Пожалуйста' -> Russian Ensemble model, conf: 0.450)\n",
      "'Я не понимаю' -> Russian Ensemble model, conf: 0.593)\n",
      "'Можете повторить?' -> Russian Ensemble model, conf: 0.707)\n",
      "'Как вас зовут?' -> Russian Ensemble model, conf: 0.343)\n",
      "Original results:\n",
      "'Hello, how are you today?' -> English (original model)\n",
      "'What's the weather like?' -> English (original model)\n",
      "'Thank you very much' -> Cornish (original model)\n",
      "'Nice to meet you' -> Scots (original model)\n",
      "'Have a great day' -> Guarani (original model)\n",
      "'How was your weekend?' -> Afrikaans (original model)\n",
      "'I'm doing well, thanks' -> Xhosa (original model)\n",
      "'See you later' -> English (original model)\n",
      "'Good morning everyone' -> English (original model)\n",
      "'Can you help me please?' -> Chavacano (original model)\n",
      "'I love this song' -> English (original model)\n",
      "'What time is it?' -> Tetum (original model)\n",
      "'Where are you from?' -> English (original model)\n",
      "'How much does this cost?' -> English (original model)\n",
      "'I'm hungry, let's eat' -> Malay (original model)\n",
      "'Excuse me' -> Latin (original model)\n",
      "'You're welcome' -> Chavacano (original model)\n",
      "'I don't understand' -> German (original model)\n",
      "'Could you repeat that?' -> English (original model)\n",
      "'What's your name?' -> English (original model)\n",
      "'Hola, ¿cómo estás?' -> Extremaduran (original model)\n",
      "'¿Qué tal el tiempo?' -> Extremaduran (original model)\n",
      "'Muchas gracias' -> Extremaduran (original model)\n",
      "'Mucho gusto' -> Irish (original model)\n",
      "'Que tengas buen día' -> Extremaduran (original model)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Extremaduran (original model)\n",
      "'Estoy bien, gracias' -> Spanish (original model)\n",
      "'Hasta luego' -> Extremaduran (original model)\n",
      "'Buenos días a todos' -> Galician (original model)\n",
      "'¿Me puedes ayudar?' -> Asturian (original model)\n",
      "'Me encanta esta canción' -> Aragonese (original model)\n",
      "'¿Qué hora es?' -> Arpitan (original model)\n",
      "'¿De dónde eres?' -> Spanish (original model)\n",
      "'¿Cuánto cuesta esto?' -> Extremaduran (original model)\n",
      "'Tengo hambre, vamos a comer' -> Portuguese (original model)\n",
      "'Disculpe' -> Friulian (original model)\n",
      "'De nada' -> Romansh (original model)\n",
      "'No entiendo' -> West Low German (original model)\n",
      "'¿Puedes repetir eso?' -> French (original model)\n",
      "'¿Cómo te llamas?' -> Extremaduran (original model)\n",
      "'Bonjour, comment allez-vous?' -> French (original model)\n",
      "'Quel temps fait-il?' -> French (original model)\n",
      "'Merci beaucoup' -> French (original model)\n",
      "'Enchanté' -> Irish (original model)\n",
      "'Passez une bonne journée' -> French (original model)\n",
      "'Comment s'est passé votre weekend?' -> Afrikaans (original model)\n",
      "'Je vais bien, merci' -> Latvian (original model)\n",
      "'À bientôt' -> Arpitan (original model)\n",
      "'Bonjour tout le monde' -> Saterfriesisch (original model)\n",
      "'Pouvez-vous m'aider?' -> Narom (original model)\n",
      "'J'adore cette chanson' -> Tarantino dialect (original model)\n",
      "'Quelle heure est-il?' -> French (original model)\n",
      "'D'où venez-vous?' -> Breton (original model)\n",
      "'Combien ça coûte?' -> Ligurian (original model)\n",
      "'J'ai faim, allons manger' -> Xhosa (original model)\n",
      "'Excusez-moi' -> Lojban (original model)\n",
      "'De rien' -> Zeeuws (original model)\n",
      "'Je ne comprends pas' -> Portuguese (original model)\n",
      "'Pouvez-vous répéter?' -> Narom (original model)\n",
      "'Comment vous appelez-vous?' -> French (original model)\n",
      "'Hallo, wie geht es dir?' -> German (original model)\n",
      "'Wie ist das Wetter?' -> Western Frisian (original model)\n",
      "'Vielen Dank' -> Livvi-Karelian (original model)\n",
      "'Freut mich' -> German (original model)\n",
      "'Schönen Tag noch' -> Ripuarisch (original model)\n",
      "'Wie war dein Wochenende?' -> German (original model)\n",
      "'Mir geht es gut, danke' -> Veps (original model)\n",
      "'Bis später' -> Saterfriesisch (original model)\n",
      "'Guten Morgen alle' -> Bokmål (original model)\n",
      "'Kannst du mir helfen?' -> Pennsylvania German (original model)\n",
      "'Ich liebe dieses Lied' -> German (original model)\n",
      "'Wie spät ist es?' -> Saterfriesisch (original model)\n",
      "'Woher kommst du?' -> Ripuarisch (original model)\n",
      "'Wie viel kostet das?' -> Afrikaans (original model)\n",
      "'Ich habe Hunger, lass uns essen' -> German (original model)\n",
      "'Entschuldigung' -> German (original model)\n",
      "'Bitte schön' -> Ripuarisch (original model)\n",
      "'Ich verstehe nicht' -> German (original model)\n",
      "'Können Sie das wiederholen?' -> Low German (original model)\n",
      "'Wie heißen Sie?' -> German (original model)\n",
      "'Привет, как дела?' -> Macedonian (original model)\n",
      "'Какая погода?' -> Russian (original model)\n",
      "'Большое спасибо' -> Russian (original model)\n",
      "'Приятно познакомиться' -> Russian (original model)\n",
      "'Хорошего дня' -> Russian (original model)\n",
      "'Как прошли выходные?' -> Russian (original model)\n",
      "'У меня всё хорошо, спасибо' -> Russian (original model)\n",
      "'Увидимся позже' -> Ukrainian (original model)\n",
      "'Доброе утро всем' -> Russian (original model)\n",
      "'Можете мне помочь?' -> Russian (original model)\n",
      "'Мне нравится эта песня' -> Russian (original model)\n",
      "'Который час?' -> Rusyn (original model)\n",
      "'Откуда вы?' -> Rusyn (original model)\n",
      "'Сколько это стоит?' -> Erzya (original model)\n",
      "'Я голоден, давайте поедим' -> Bulgarian (original model)\n",
      "'Извините' -> Bulgarian (original model)\n",
      "'Пожалуйста' -> Ukrainian (original model)\n",
      "'Я не понимаю' -> Ukrainian (original model)\n",
      "'Можете повторить?' -> Russian (original model)\n",
      "'Как вас зовут?' -> Moksha (original model)\n",
      "Oversampled Results:\n",
      "'Hello, how are you today?' -> English (Oversampled model)\n",
      "'What's the weather like?' -> English (Oversampled model)\n",
      "'Thank you very much' -> English (Oversampled model)\n",
      "'Nice to meet you' -> English (Oversampled model)\n",
      "'Have a great day' -> English (Oversampled model)\n",
      "'How was your weekend?' -> English (Oversampled model)\n",
      "'I'm doing well, thanks' -> English (Oversampled model)\n",
      "'See you later' -> English (Oversampled model)\n",
      "'Good morning everyone' -> English (Oversampled model)\n",
      "'Can you help me please?' -> English (Oversampled model)\n",
      "'I love this song' -> English (Oversampled model)\n",
      "'What time is it?' -> English (Oversampled model)\n",
      "'Where are you from?' -> English (Oversampled model)\n",
      "'How much does this cost?' -> English (Oversampled model)\n",
      "'I'm hungry, let's eat' -> German (Oversampled model)\n",
      "'Excuse me' -> Latin (Oversampled model)\n",
      "'You're welcome' -> English (Oversampled model)\n",
      "'I don't understand' -> German (Oversampled model)\n",
      "'Could you repeat that?' -> English (Oversampled model)\n",
      "'What's your name?' -> English (Oversampled model)\n",
      "'Hola, ¿cómo estás?' -> Spanish (Oversampled model)\n",
      "'¿Qué tal el tiempo?' -> Spanish (Oversampled model)\n",
      "'Muchas gracias' -> Spanish (Oversampled model)\n",
      "'Mucho gusto' -> English (Oversampled model)\n",
      "'Que tengas buen día' -> Spanish (Oversampled model)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Spanish (Oversampled model)\n",
      "'Estoy bien, gracias' -> Spanish (Oversampled model)\n",
      "'Hasta luego' -> Spanish (Oversampled model)\n",
      "'Buenos días a todos' -> Spanish (Oversampled model)\n",
      "'¿Me puedes ayudar?' -> Spanish (Oversampled model)\n",
      "'Me encanta esta canción' -> Spanish (Oversampled model)\n",
      "'¿Qué hora es?' -> Spanish (Oversampled model)\n",
      "'¿De dónde eres?' -> Spanish (Oversampled model)\n",
      "'¿Cuánto cuesta esto?' -> Spanish (Oversampled model)\n",
      "'Tengo hambre, vamos a comer' -> Portuguese (Oversampled model)\n",
      "'Disculpe' -> Spanish (Oversampled model)\n",
      "'De nada' -> Portuguese (Oversampled model)\n",
      "'No entiendo' -> Spanish (Oversampled model)\n",
      "'¿Puedes repetir eso?' -> French (Oversampled model)\n",
      "'¿Cómo te llamas?' -> Spanish (Oversampled model)\n",
      "'Bonjour, comment allez-vous?' -> French (Oversampled model)\n",
      "'Quel temps fait-il?' -> French (Oversampled model)\n",
      "'Merci beaucoup' -> French (Oversampled model)\n",
      "'Enchanté' -> French (Oversampled model)\n",
      "'Passez une bonne journée' -> French (Oversampled model)\n",
      "'Comment s'est passé votre weekend?' -> French (Oversampled model)\n",
      "'Je vais bien, merci' -> French (Oversampled model)\n",
      "'À bientôt' -> French (Oversampled model)\n",
      "'Bonjour tout le monde' -> French (Oversampled model)\n",
      "'Pouvez-vous m'aider?' -> French (Oversampled model)\n",
      "'J'adore cette chanson' -> French (Oversampled model)\n",
      "'Quelle heure est-il?' -> French (Oversampled model)\n",
      "'D'où venez-vous?' -> Breton (Oversampled model)\n",
      "'Combien ça coûte?' -> Spanish (Oversampled model)\n",
      "'J'ai faim, allons manger' -> English (Oversampled model)\n",
      "'Excusez-moi' -> Lojban (Oversampled model)\n",
      "'De rien' -> German (Oversampled model)\n",
      "'Je ne comprends pas' -> Portuguese (Oversampled model)\n",
      "'Pouvez-vous répéter?' -> French (Oversampled model)\n",
      "'Comment vous appelez-vous?' -> French (Oversampled model)\n",
      "'Hallo, wie geht es dir?' -> German (Oversampled model)\n",
      "'Wie ist das Wetter?' -> German (Oversampled model)\n",
      "'Vielen Dank' -> German (Oversampled model)\n",
      "'Freut mich' -> German (Oversampled model)\n",
      "'Schönen Tag noch' -> German (Oversampled model)\n",
      "'Wie war dein Wochenende?' -> German (Oversampled model)\n",
      "'Mir geht es gut, danke' -> German (Oversampled model)\n",
      "'Bis später' -> German (Oversampled model)\n",
      "'Guten Morgen alle' -> German (Oversampled model)\n",
      "'Kannst du mir helfen?' -> German (Oversampled model)\n",
      "'Ich liebe dieses Lied' -> German (Oversampled model)\n",
      "'Wie spät ist es?' -> German (Oversampled model)\n",
      "'Woher kommst du?' -> German (Oversampled model)\n",
      "'Wie viel kostet das?' -> German (Oversampled model)\n",
      "'Ich habe Hunger, lass uns essen' -> German (Oversampled model)\n",
      "'Entschuldigung' -> German (Oversampled model)\n",
      "'Bitte schön' -> German (Oversampled model)\n",
      "'Ich verstehe nicht' -> German (Oversampled model)\n",
      "'Können Sie das wiederholen?' -> German (Oversampled model)\n",
      "'Wie heißen Sie?' -> German (Oversampled model)\n",
      "'Привет, как дела?' -> Russian (Oversampled model)\n",
      "'Какая погода?' -> Russian (Oversampled model)\n",
      "'Большое спасибо' -> Russian (Oversampled model)\n",
      "'Приятно познакомиться' -> Russian (Oversampled model)\n",
      "'Хорошего дня' -> Russian (Oversampled model)\n",
      "'Как прошли выходные?' -> Russian (Oversampled model)\n",
      "'У меня всё хорошо, спасибо' -> Russian (Oversampled model)\n",
      "'Увидимся позже' -> Russian (Oversampled model)\n",
      "'Доброе утро всем' -> Russian (Oversampled model)\n",
      "'Можете мне помочь?' -> Russian (Oversampled model)\n",
      "'Мне нравится эта песня' -> Russian (Oversampled model)\n",
      "'Который час?' -> Russian (Oversampled model)\n",
      "'Откуда вы?' -> Russian (Oversampled model)\n",
      "'Сколько это стоит?' -> Russian (Oversampled model)\n",
      "'Я голоден, давайте поедим' -> Russian (Oversampled model)\n",
      "'Извините' -> Russian (Oversampled model)\n",
      "'Пожалуйста' -> Russian (Oversampled model)\n",
      "'Я не понимаю' -> Russian (Oversampled model)\n",
      "'Можете повторить?' -> Russian (Oversampled model)\n",
      "'Как вас зовут?' -> Russian (Oversampled model)\n",
      "Word N-Gram Results:\n",
      "'Hello, how are you today?' -> Avar (Word N-gram model)\n",
      "'What's the weather like?' -> English (Word N-gram model)\n",
      "'Thank you very much' -> Avar (Word N-gram model)\n",
      "'Nice to meet you' -> Avar (Word N-gram model)\n",
      "'Have a great day' -> English (Word N-gram model)\n",
      "'How was your weekend?' -> English (Word N-gram model)\n",
      "'I'm doing well, thanks' -> Luxembourgish (Word N-gram model)\n",
      "'See you later' -> Avar (Word N-gram model)\n",
      "'Good morning everyone' -> West Low German (Word N-gram model)\n",
      "'Can you help me please?' -> Avar (Word N-gram model)\n",
      "'I love this song' -> English (Word N-gram model)\n",
      "'What time is it?' -> English (Word N-gram model)\n",
      "'Where are you from?' -> English (Word N-gram model)\n",
      "'How much does this cost?' -> English (Word N-gram model)\n",
      "'I'm hungry, let's eat' -> Czech (Word N-gram model)\n",
      "'Excuse me' -> Fiji Hindi (Word N-gram model)\n",
      "'You're welcome' -> Avar (Word N-gram model)\n",
      "'I don't understand' -> Irish (Word N-gram model)\n",
      "'Could you repeat that?' -> Avar (Word N-gram model)\n",
      "'What's your name?' -> Avar (Word N-gram model)\n",
      "'Hola, ¿cómo estás?' -> Polish (Word N-gram model)\n",
      "'¿Qué tal el tiempo?' -> Classical Nahuatl (Word N-gram model)\n",
      "'Muchas gracias' -> Polish (Word N-gram model)\n",
      "'Mucho gusto' -> Polish (Word N-gram model)\n",
      "'Que tengas buen día' -> Galician (Word N-gram model)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Aromanian (Word N-gram model)\n",
      "'Estoy bien, gracias' -> Asturian (Word N-gram model)\n",
      "'Hasta luego' -> Spanish (Word N-gram model)\n",
      "'Buenos días a todos' -> Guarani (Word N-gram model)\n",
      "'¿Me puedes ayudar?' -> Fiji Hindi (Word N-gram model)\n",
      "'Me encanta esta canción' -> Fiji Hindi (Word N-gram model)\n",
      "'¿Qué hora es?' -> Classical Nahuatl (Word N-gram model)\n",
      "'¿De dónde eres?' -> Mirandese (Word N-gram model)\n",
      "'¿Cuánto cuesta esto?' -> Dimli (Word N-gram model)\n",
      "'Tengo hambre, vamos a comer' -> Polish (Word N-gram model)\n",
      "'Disculpe' -> Polish (Word N-gram model)\n",
      "'De nada' -> Mirandese (Word N-gram model)\n",
      "'No entiendo' -> Latvian (Word N-gram model)\n",
      "'¿Puedes repetir eso?' -> Classical Nahuatl (Word N-gram model)\n",
      "'¿Cómo te llamas?' -> Maori (Word N-gram model)\n",
      "'Bonjour, comment allez-vous?' -> Polish (Word N-gram model)\n",
      "'Quel temps fait-il?' -> French (Word N-gram model)\n",
      "'Merci beaucoup' -> Polish (Word N-gram model)\n",
      "'Enchanté' -> Polish (Word N-gram model)\n",
      "'Passez une bonne journée' -> French (Word N-gram model)\n",
      "'Comment s'est passé votre weekend?' -> Latin (Word N-gram model)\n",
      "'Je vais bien, merci' -> Slovene (Word N-gram model)\n",
      "'À bientôt' -> Polish (Word N-gram model)\n",
      "'Bonjour tout le monde' -> French (Word N-gram model)\n",
      "'Pouvez-vous m'aider?' -> Polish (Word N-gram model)\n",
      "'J'adore cette chanson' -> French (Word N-gram model)\n",
      "'Quelle heure est-il?' -> French (Word N-gram model)\n",
      "'D'où venez-vous?' -> Polish (Word N-gram model)\n",
      "'Combien ça coûte?' -> Polish (Word N-gram model)\n",
      "'J'ai faim, allons manger' -> Maori (Word N-gram model)\n",
      "'Excusez-moi' -> Lojban (Word N-gram model)\n",
      "'De rien' -> Mirandese (Word N-gram model)\n",
      "'Je ne comprends pas' -> Bosnian (Word N-gram model)\n",
      "'Pouvez-vous répéter?' -> Polish (Word N-gram model)\n",
      "'Comment vous appelez-vous?' -> Polish (Word N-gram model)\n",
      "'Hallo, wie geht es dir?' -> Pennsylvania German (Word N-gram model)\n",
      "'Wie ist das Wetter?' -> Pampanga (Word N-gram model)\n",
      "'Vielen Dank' -> Polish (Word N-gram model)\n",
      "'Freut mich' -> Polish (Word N-gram model)\n",
      "'Schönen Tag noch' -> Ripuarisch (Word N-gram model)\n",
      "'Wie war dein Wochenende?' -> German (Word N-gram model)\n",
      "'Mir geht es gut, danke' -> Pennsylvania German (Word N-gram model)\n",
      "'Bis später' -> German (Word N-gram model)\n",
      "'Guten Morgen alle' -> Danish (Word N-gram model)\n",
      "'Kannst du mir helfen?' -> Karakalpak (Word N-gram model)\n",
      "'Ich liebe dieses Lied' -> Slovak (Word N-gram model)\n",
      "'Wie spät ist es?' -> Pampanga (Word N-gram model)\n",
      "'Woher kommst du?' -> French (Word N-gram model)\n",
      "'Wie viel kostet das?' -> Pampanga (Word N-gram model)\n",
      "'Ich habe Hunger, lass uns essen' -> Pennsylvania German (Word N-gram model)\n",
      "'Entschuldigung' -> Polish (Word N-gram model)\n",
      "'Bitte schön' -> Polish (Word N-gram model)\n",
      "'Ich verstehe nicht' -> Pampanga (Word N-gram model)\n",
      "'Können Sie das wiederholen?' -> Pampanga (Word N-gram model)\n",
      "'Wie heißen Sie?' -> Pennsylvania German (Word N-gram model)\n",
      "'Привет, как дела?' -> Russian (Word N-gram model)\n",
      "'Какая погода?' -> Polish (Word N-gram model)\n",
      "'Большое спасибо' -> Polish (Word N-gram model)\n",
      "'Приятно познакомиться' -> Polish (Word N-gram model)\n",
      "'Хорошего дня' -> Polish (Word N-gram model)\n",
      "'Как прошли выходные?' -> Russian (Word N-gram model)\n",
      "'У меня всё хорошо, спасибо' -> Polish (Word N-gram model)\n",
      "'Увидимся позже' -> Polish (Word N-gram model)\n",
      "'Доброе утро всем' -> Polish (Word N-gram model)\n",
      "'Можете мне помочь?' -> Polish (Word N-gram model)\n",
      "'Мне нравится эта песня' -> Polish (Word N-gram model)\n",
      "'Который час?' -> Ukrainian (Word N-gram model)\n",
      "'Откуда вы?' -> Polish (Word N-gram model)\n",
      "'Сколько это стоит?' -> Polish (Word N-gram model)\n",
      "'Я голоден, давайте поедим' -> Polish (Word N-gram model)\n",
      "'Извините' -> Polish (Word N-gram model)\n",
      "'Пожалуйста' -> Polish (Word N-gram model)\n",
      "'Я не понимаю' -> Russian (Word N-gram model)\n",
      "'Можете повторить?' -> Polish (Word N-gram model)\n",
      "'Как вас зовут?' -> Russian (Word N-gram model)\n",
      "\n",
      "=== Per-language scores for generalization data ===\n",
      "\n",
      "ENSEMBLE MODEL:\n",
      "English: 18/20 (0.900)\n",
      "Spanish: 15/20 (0.750)\n",
      "French: 15/20 (0.750)\n",
      "German: 20/20 (1.000)\n",
      "Russian: 20/20 (1.000)\n",
      "\n",
      "ORIGINAL MODEL:\n",
      "English: 9/20 (0.450)\n",
      "Spanish: 2/20 (0.100)\n",
      "French: 6/20 (0.300)\n",
      "German: 8/20 (0.400)\n",
      "Russian: 10/20 (0.500)\n",
      "\n",
      "OVERSAMPLED MODEL:\n",
      "English: 17/20 (0.850)\n",
      "Spanish: 16/20 (0.800)\n",
      "French: 14/20 (0.700)\n",
      "German: 20/20 (1.000)\n",
      "Russian: 20/20 (1.000)\n",
      "\n",
      "WORD_NGRAM MODEL:\n",
      "English: 7/20 (0.350)\n",
      "Spanish: 1/20 (0.050)\n",
      "French: 5/20 (0.250)\n",
      "German: 2/20 (0.100)\n",
      "Russian: 4/20 (0.200)\n"
     ]
    }
   ],
   "source": [
    "# Track scores in a dict\n",
    "scores = {\n",
    "    \"ensemble\": defaultdict(lambda: [0, 0]),  \n",
    "    \"original\": defaultdict(lambda: [0, 0]),\n",
    "    \"oversampled\": defaultdict(lambda: [0, 0]),\n",
    "    \"word_ngram\": defaultdict(lambda: [0, 0]),\n",
    "}\n",
    "# Random short conversational texts generated (by Claude) for some common languages to see how well the models generalize\n",
    "with open('common_phrases.json', 'r', encoding='utf-8') as f: phrases_data = json.load(f)\n",
    "# Flatten phrases into (lang_code, phrase) pairs\n",
    "test_data = [(lang_code, phrase) for lang_code, phrases in phrases_data.items() for phrase in phrases]\n",
    "\n",
    "# Below\n",
    "# Use vectorizer -> Make the prediction -> Get the full language name -> update number in dictionary -> right or wrong?\n",
    "\n",
    "print(\"Ensemble Results:\")\n",
    "for lang_code, phrase in test_data:\n",
    "    pred, conf = ensemble_predict(phrase)\n",
    "    lang_name = label_map.get(pred, pred)\n",
    "    print(f\"'{phrase}' -> {lang_name} Ensemble model, conf: {conf:.3f})\")\n",
    "\n",
    "    scores[\"ensemble\"][lang_code][1] += 1\n",
    "    if pred == lang_code:\n",
    "        scores[\"ensemble\"][lang_code][0] += 1\n",
    "\n",
    "print(\"Original results:\")\n",
    "for lang_code, phrase in test_data:\n",
    "    orig_features = vectorizer.transform([phrase])\n",
    "    orig_pred = naive_bayes_model.predict(orig_features)[0]\n",
    "    lang_name = label_map.get(orig_pred, orig_pred)\n",
    "    print(f\"'{phrase}' -> {lang_name} (original model)\")\n",
    "\n",
    "    scores[\"original\"][lang_code][1] += 1\n",
    "    if orig_pred == lang_code:\n",
    "        scores[\"original\"][lang_code][0] += 1\n",
    "\n",
    "print(\"Oversampled Results:\")\n",
    "for lang_code, phrase in test_data:\n",
    "    over_features = over_vectorizer.transform([phrase])\n",
    "    over_pred = naive_bayes_model_over.predict(over_features)[0]\n",
    "    lang_name = label_map.get(over_pred, over_pred)\n",
    "    print(f\"'{phrase}' -> {lang_name} (Oversampled model)\")\n",
    "\n",
    "    scores[\"oversampled\"][lang_code][1] += 1\n",
    "    if over_pred == lang_code:\n",
    "        scores[\"oversampled\"][lang_code][0] += 1\n",
    "\n",
    "print(\"Word N-Gram Results:\")\n",
    "for lang_code, phrase in test_data:\n",
    "    word_features = word_vectorizer.transform([phrase])\n",
    "    word_pred = naive_bayes_model_word.predict(word_features)[0]\n",
    "    lang_name = label_map.get(word_pred, word_pred)\n",
    "    print(f\"'{phrase}' -> {lang_name} (Word N-gram model)\")\n",
    "\n",
    "    scores[\"word_ngram\"][lang_code][1] += 1\n",
    "    if word_pred == lang_code:\n",
    "        scores[\"word_ngram\"][lang_code][0] += 1\n",
    "\n",
    "# Print the score each model achieved\n",
    "print(\"\\n=== Per-language scores for generalization data ===\")\n",
    "for model_name, lang_scores in scores.items():\n",
    "    print(f\"\\n{model_name.upper()} MODEL:\")\n",
    "    for lang_code, (correct, total) in lang_scores.items():\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "        lang_name = label_map.get(lang_code, lang_code)\n",
    "        print(f\"{lang_name}: {correct}/{total} ({acc:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3c5a4",
   "metadata": {},
   "source": [
    "## Test the models on the final test set and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83eb8768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerliddell/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Metrics:\n",
      "Original Model -> Acc: 0.9121, Precision: 0.9394, Recall: 0.9121, F1: 0.9170\n",
      "Oversampled Model -> Acc: 0.7719, Precision: 0.9037, Recall: 0.7719, F1: 0.7825\n",
      "Ensemble Model -> Acc: 0.8075, Precision: 0.9288, Recall: 0.8075, F1: 0.8207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerliddell/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Load final test set\n",
    "with open('wiki_languages/x_test.txt', 'r', encoding='utf-8') as file:\n",
    "    final_test_data = [line.strip() for line in file.readlines()]\n",
    "\n",
    "final_test_data = pd.DataFrame(final_test_data, columns=['text'])\n",
    "\n",
    "#Copy and normalize text\n",
    "final_test_data_copy = final_test_data.copy()\n",
    "final_test_data['text'] = final_test_data['text'].apply(normalize_text)\n",
    "\n",
    "#Load labels\n",
    "with open('wiki_languages/y_test.txt', 'r', encoding='utf-8') as file:\n",
    "    final_test_labels = [line.strip() for line in file.readlines()]\n",
    "\n",
    "final_test_labels = pd.Series(final_test_labels, name='label')\n",
    "final_test_data['label'] = final_test_labels\n",
    "\n",
    "#Original Model\n",
    "final_test_tfidf = vectorizer.transform(final_test_data['text'])\n",
    "orig_pred = naive_bayes_model.predict(final_test_tfidf)\n",
    "\n",
    "orig_acc = accuracy_score(final_test_data['label'], orig_pred)\n",
    "orig_prec, orig_rec, orig_f1, _ = precision_recall_fscore_support(\n",
    "    final_test_data['label'], orig_pred, average='weighted'\n",
    ")\n",
    "\n",
    "#Oversampled Model\n",
    "final_test_tfidf_over = over_vectorizer.transform(final_test_data['text'])\n",
    "over_pred = naive_bayes_model_over.predict(final_test_tfidf_over)\n",
    "\n",
    "over_acc = accuracy_score(final_test_data['label'], over_pred)\n",
    "over_prec, over_rec, over_f1, _ = precision_recall_fscore_support(\n",
    "    final_test_data['label'], over_pred, average='weighted'\n",
    ")\n",
    "\n",
    "#Ensemble Model\n",
    "ensemble_pred = []\n",
    "for text in final_test_data['text']:\n",
    "    pred, _ = ensemble_predict(text)\n",
    "    ensemble_pred.append(pred)\n",
    "\n",
    "ens_acc = accuracy_score(final_test_data['label'], ensemble_pred)\n",
    "ens_prec, ens_rec, ens_f1, _ = precision_recall_fscore_support(\n",
    "    final_test_data['label'], ensemble_pred, average='weighted'\n",
    ")\n",
    "\n",
    "# Print out the metrics\n",
    "print(\"\\nFinal Test Set Metrics:\")\n",
    "print(f\"Original Model -> Acc: {orig_acc:.4f}, Precision: {orig_prec:.4f}, Recall: {orig_rec:.4f}, F1: {orig_f1:.4f}\")\n",
    "print(f\"Oversampled Model -> Acc: {over_acc:.4f}, Precision: {over_prec:.4f}, Recall: {over_rec:.4f}, F1: {over_f1:.4f}\")\n",
    "print(f\"Ensemble Model -> Acc: {ens_acc:.4f}, Precision: {ens_prec:.4f}, Recall: {ens_rec:.4f}, F1: {ens_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df0356",
   "metadata": {},
   "source": [
    "## Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "becd3888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_over_vectorizer.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the oversampled model, traditional model and vectorizer using joblib\n",
    "# Will create the same logic in the \n",
    "\n",
    "joblib.dump(naive_bayes_model, 'naive_bayes_model.joblib')\n",
    "joblib.dump(naive_bayes_model_over, 'naive_bayes_model_over.joblib')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
    "joblib.dump(over_vectorizer, 'tfidf_over_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e94222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
