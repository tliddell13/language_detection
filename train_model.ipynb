{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d67b4a",
   "metadata": {},
   "source": [
    "# Language Detection Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82feb43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import joblib\n",
    "import unicodedata\n",
    "import json\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83982a",
   "metadata": {},
   "source": [
    "## Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde6bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0  Klement Gottwaldi surnukeha palsameeriti ning ...   est\n",
      "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....   swe\n",
      "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...   mai\n",
      "3  Après lo cort periòde d'establiment a Basilèa,...   oci\n",
      "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...   tha\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "I decided to use the Wikipedia Language Identification Benchmark dataset to train my model. \n",
    "The dataset can be found at\n",
    "https://www.kaggle.com/datasets/mexwell/wili-2018?resource=download\n",
    "It is composed of 235 languages, with 1000 samples per language, equaling 235,000 total samples.\n",
    "\"\"\"\n",
    "\n",
    "# Read the text file of data by each line into a list\n",
    "with open('wiki_languages/x_train.txt', 'r', encoding='utf-8') as file:\n",
    "    data = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "data = pd.DataFrame(data, columns=['text'])\n",
    "\n",
    "# Read the text file of labels by each line into a list\n",
    "with open('wiki_languages/y_train.txt', 'r', encoding='utf-8') as file:\n",
    "    labels = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Convert the labels list to a series\n",
    "labels = pd.Series(labels, name='label')\n",
    "\n",
    "# Combine the data and labels into a single DataFrame\n",
    "data['label'] = labels\n",
    "\n",
    "# lets take a look at what the first few rows of the dataset look like\n",
    "print(data.head())\n",
    "\n",
    "# Try some preprocessing steps out\n",
    "# Get rid of extra whitespace\n",
    "data['text'] = data['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "# More thorough text normalization function\n",
    "def normalize_text(text):\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove URL patterns, email addresses. Probably not common in the dataset, but won't hurt\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove numbers (language-agnostic)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation clusters\n",
    "    text = re.sub(r'[^\\w\\s]{2,}', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# The extra preprocessing didn't have much effect\n",
    "#data['text'] = data['text'].apply(normalize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3370c4",
   "metadata": {},
   "source": [
    "## N - Gram -> TF-IDF -> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7175897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (94000, 10000)\n",
      "Testing data shape: (23500, 10000)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "First I decided to implement a pipeline that uses:\n",
    "N - Grams -> TF-IDF -> Multinomial Naive Bayes\n",
    "N-Grams were used for text categorization in the paper\n",
    "\"N-Gram-Based Text Categorization\" by Cavnar and Trenkle (1994). \n",
    "Found here: https://dsacl3-2019.github.io/materials/CavnarTrenkle.pdf\n",
    "\"\"\"    \n",
    "\n",
    "# Split the data into training and testing sets (The actual test set will be used later to compare both models)\n",
    "# 80 - 20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Make a copy of the test so I can look at the actual text later\n",
    "X_test_copy = X_test.copy()\n",
    "\"\"\"\n",
    "TF-IDF is an excellent choice for language classification because it is able to capture the importance of words (or n-grams) in a sentence relative to a collection of documents (corpus).\n",
    "\n",
    "Setting the n-gram range had the most impact on the accuracy of the model.\n",
    "The other parameters had little effect on the accuracy.\n",
    "Without setting the max features, there are over 1 million features, but the model performs similarly with 10,000 features.\n",
    "\"\"\"\n",
    "# Create the TF-IDF Vectorizer with N-Grams \n",
    "# Experimenting with different n-gram ranges\n",
    "# 92 percent accuracy with (1,3)\n",
    "# 92 percent accuracy with (1,4) as well, but takes longer to train\n",
    "# 90 percent accuracy with (2,2)\n",
    "# 91 percent accuracy with (3,3)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char', max_features=10000)\n",
    "\n",
    "# Fit and transform the training data, then transform the test data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(f'Training data shape: {X_train_tfidf.shape}')\n",
    "print(f'Testing data shape: {X_test_tfidf.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9381d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 22520.618746050455), ('a', 14703.707822661685), ('e', 11723.248816744837), ('i', 10203.286942424775), ('n', 9738.401140217398), ('o', 7082.061813470186), ('r', 7026.917202993776), ('s', 6800.151717350656), ('t', 6723.138997205867), ('l', 5659.852411781818), ('u', 5162.535088148394), ('d', 4971.675171340961), ('а', 4107.420609403408), ('m', 4036.598865746633), ('k', 3869.326476303116), ('a ', 3675.4808160780594), ('e ', 3311.1022013198017), ('g', 3275.1563718632424), ('h', 3246.55476560796), ('c', 3178.0178693559265)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at what the TF-IDF gave us:\n",
    "# Lets take a look at some of the most distinctive (TF-IDF score) n-grams across the entire training set\n",
    "sum_words = X_train_tfidf.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "common_words = words_freq[:20]  \n",
    "print(common_words)\n",
    "df_common_words = pd.DataFrame(common_words, columns=['N-Gram', 'TF-IDF Score'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TF-IDF Score', y='N-Gram', data=df_common_words)\n",
    "plt.title('Top 20 N-Grams by TF-IDF Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4074bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9220\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multinomial Naive Bayes is a good choice for text classification tasks, especially when dealing with discrete features like word counts or frequencies.\n",
    "It also works well with the TF-IDF representation of text data.\n",
    "\"\"\"\n",
    "# Now I will train a Multinomial Naive Bayes model on the TF-IDF transformed data\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train_tfidf, y_train)\n",
    "y_pred = naive_bayes_model.predict(X_test_tfidf)\n",
    "\n",
    "# Check the performance of the model using a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfef3583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: Konkani (kok) - Predicted: Marathi (mar)\n",
      "Text Sample: गांवांत २ शासकीय पूर्व-प्राथमिक शाळा आसा. ﻿गांवांत १ शासकीय प्राथमिक शाळा आसा. ﻿गांवांत १ शासकीय कनिष्ठ माध्यमिक शाळा आसा. ﻿गांवांत १ शासकीय माध्यमिक शाळा आसा. सगळ्यांत लागीं उच्च माध्यमिक शाळा (BALI) १० किलोमिटर परस चड अंतराचेर आसा. सगळ्यांत लागीं पदवी महाविद्यालय (CUNCOLIM) ५ ते १० किलोमिटराच्या अंतराचेर आसा. सगळ्यांत लागीं अभियांत्रिकी महाविद्यालय (BANDORA CT) १० किलोमिटर परस चड अंतराचेर आसा. सगळ्यांत लागीं वैजकी महाविद्यालय (BAMBOLIM CT) १० किलोमिटर परस चड अंतराचेर आसा. सगळ्यांत लागीं वैवस्थापन संस्था (MARGAO) १० किलोमिटर परस चड अंतराचेर आसा. सगळ्यांत लागीं पॉलिटेक्निक (CURCHOREM-CACORA) १० किलोमिटर परस चड अंतराचेर आसा. सगळ्यांत लागीं वेवसायिक प्रशिक्षण शाळा (CANACONA) १० किलोमिटर परस चड अंतराचेर आसा. सगळ्यांत लागीं अनौपचारिक प्रशिक्षणकेंद्र (MARGAO) १० किलोमिटर परस चड अंतराचेर आसा. सगळ्यांत लागीं अपंगांखातीर खाशेली शाळा (MARGAO) १० किलोमिटर परस चड अंतराचेर आसा.\n",
      "\n",
      "\n",
      "True: Belarusian (bel) - Predicted: Belarusian (Taraschkewiza) (be-tarask)\n",
      "Text Sample: У каледжа вельмі паважная рэпутацыя, многія члены брытанскай каралеўскай сям'і з'яўляліся яго выпускнікамі: кароль Эдуард VII, кароль Георг VI, прынц Генры, герцаг Глостэрскі і Чарльз, прынц Уэльскі.\n",
      "\n",
      "\n",
      "True: Erzya (myv) - Predicted: Russian (rus)\n",
      "Text Sample: Специфические принципы изучения словообразования в вузе (на материале мордовских языков). // Научные издания Московского Венгерского Колледжа. – М.: Валанг. Ч. 2, 2002. – С. 268-279.\n",
      "\n",
      "\n",
      "True: Gilaki (glk) - Predicted: Persian (fas)\n",
      "Text Sample: تاریخچه: ا پرنده ی اولین دفا ایته زیست شناس کی اونی نام سرجان گلد بو، 1840 میلادی ببرده به انگلستان. بعد انی موتقاضی زیاده بوست و کشتیانه زیادی دست به کار انتقال ا پرنده یان بوبوستیدی کی اشنه ویشتر بردیدی اروپا بخصوص انگلستان، هلند، بلژیک. اشنه او موقا در دسته های چند ده هیزارتایی حمل کودیدی و در طول او سفر چند هفته ای فقط تعداد کمی از اشن سالم فارسائید اروپا به زودی ا پرنده اهلی بوبوست و از طریق انگلستان انه به تومام دونیا اوسی کودد\n",
      "\n",
      "\n",
      "True: Marathi (mar) - Predicted: English (eng)\n",
      "Text Sample: The economic position of widows has been an important social issue in many societies. In societies in which the husband was typically the sole provider, his death could plunge his family into poverty. This was aggravated by women's longer life spans, and that men generally marry women younger than themselves. Many charities existed to help widows and orphans (often, not children without parents, but children without a contributing father) in need.\n",
      "\n",
      "\n",
      "True: Classical Nahuatl (nci) - Predicted: Spanish (spa)\n",
      "Text Sample: Ya no editaré con macrones, eso complica la escritura, es muy tedioso revizar los diccionarios para ver donde está la prolongación de la vocal y además no existe una regla generalizada; empezaré a editar los artículos con escritura latina sin macrones como lo hacen muchas personas en su lengua materna, es valido hacerlo por que el ISO es nah y no nci, José me gustan mucho tus propuestas de neologismos pero no hay certeza de tal aceptación en usuarios nativos.\n",
      "\n",
      "\n",
      "True: Western Panjabi (pnb) - Predicted: Persian (fas)\n",
      "Text Sample: در سال ۳۶۷ قمری عضدالدوله دیلمی وارد بغداد شد، سپس به زیارت کربلا و نجف شتافت و دستور داد مرقد عظیم و باشکوهی برای عباس بن علی بنا کنند. بنای مزبور در سال ۳۶۷ قمری آغاز شد و در سال ۳۷۲ پایان یافت و عمارت امروزه حرم عباس بن علی از عضدالدوله است که از شکوه و عظمت خاصی برخوردار است.\n",
      "\n",
      "\n",
      "True: Konkani (kok) - Predicted: English (eng)\n",
      "Text Sample: Levi-Xastr / Leviticus 16 : 11 - Aplea ani kuttumbachea patkam khatir boil bhettoita tedna, Aaron / Thus shall Aaron offer his bull for the purification offering, to make atonement for himself and for his family. When he has slaughtered it,\n",
      "\n",
      "\n",
      "True: Rusyn (rue) - Predicted: Russian (rus)\n",
      "Text Sample: Од року 1992 учитель лемковского языка в основной школѣ в Крыници. Як учитель языка и редактор лемковскых выдань активну участь мав на кодификации лемковского варианта русинского языка в Польщи.\n",
      "\n",
      "\n",
      "True: Croatian (hrv) - Predicted: Bosnian (bos)\n",
      "Text Sample: Winter je za reprezentaciju nastupio u ukupno 84 utakmice te je pritom postigao šest pogodaka. Najznačajniji gol je postigao protiv Brazila u četvrtfinalu SP-a 1994. Po broju nastupa za Nizozemsku, Winter je trenutno na osmom mjestu.\n",
      "\n",
      "\n",
      "Most common confusions:\n",
      "Chavacano -> Spanish: 57\n",
      "Konkani -> Marathi: 53\n",
      "Gilaki -> Persian: 50\n",
      "Classical Nahuatl -> Spanish: 34\n",
      "Belarusian -> Belarusian (Taraschkewiza): 27\n",
      "Nepali (macrolanguage) -> Doteli: 27\n",
      "Serbo-Croatian -> Croatian: 26\n",
      "Rusyn -> Russian: 25\n",
      "Pampanga -> German: 24\n",
      "Erzya -> Russian: 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe common confusions are languages that are very similar to each other as expected.\\nAfter looking at some of the mistakes I noticed that it is because some of the samples contain multiple languages in one sample. This may make the model more \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the labels csv to get the language names\n",
    "labels_df = pd.read_csv('wiki_languages/labels.csv', sep=';')\n",
    "# Create a mapping from label to language name\n",
    "label_map = dict(zip(labels_df['Label'], labels_df['English']))\n",
    "\n",
    "# Make a list of all the mistakes, with predicted and actual language names\n",
    "mistakes = []\n",
    "for i, (true_label, pred_label) in enumerate(zip(y_test, y_pred)):\n",
    "    if true_label != pred_label:\n",
    "        mistakes.append({\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': pred_label,\n",
    "            'true_language': label_map.get(true_label, true_label),\n",
    "            'predicted_language': label_map.get(pred_label, pred_label),\n",
    "            # The original text sample that was misclassified\n",
    "            'text_sample': X_test_copy.iloc[i]  \n",
    "        })\n",
    "\n",
    "# Print out some of the mistakes\n",
    "for mistake in mistakes[:10]:  # Print first 10 mistakes\n",
    "    print(f\"True: {mistake['true_language']} ({mistake['true_label']}) - Predicted: {mistake['predicted_language']} ({mistake['predicted_label']})\")\n",
    "    print(f\"Text Sample: {mistake['text_sample']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# What languages were most commonly confused?\n",
    "confusion_counts = {}\n",
    "for mistake in mistakes:\n",
    "    pair = (mistake['true_language'], mistake['predicted_language'])\n",
    "    if pair not in confusion_counts:\n",
    "        confusion_counts[pair] = 0\n",
    "    confusion_counts[pair] += 1\n",
    "\n",
    "# Sort by most common confusions\n",
    "sorted_confusions = sorted(confusion_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Most common confusions:\")\n",
    "for (true_lang, pred_lang), count in sorted_confusions[:10]:  # Top 10 confusions\n",
    "    print(f\"{true_lang} -> {pred_lang}: {count}\")\n",
    "\n",
    "\"\"\"\n",
    "The common confusions are languages that are very similar to each other as expected.\n",
    "After looking at some of the mistakes I noticed that it is because some of the samples contain multiple languages in one sample. This may make the model more \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec83d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Set Accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "# Lets see it on the final test set now\n",
    "with open('wiki_languages/x_test.txt', 'r', encoding='utf-8') as file:\n",
    "    final_test_data = [line.strip() for line in file.readlines()]\n",
    "\n",
    "final_test_data = pd.DataFrame(final_test_data, columns=['text'])\n",
    "\n",
    "with open('wiki_languages/y_test.txt', 'r', encoding='utf-8') as file:\n",
    "    final_test_labels = [line.strip() for line in file.readlines()]\n",
    "\n",
    "final_test_labels = pd.Series(final_test_labels, name='label')\n",
    "\n",
    "final_test_data['label'] = final_test_labels\n",
    "\n",
    "# Transform the final test data using the same vectorizer\n",
    "final_test_tfidf = vectorizer.transform(final_test_data['text'])\n",
    "final_test_pred = naive_bayes_model.predict(final_test_tfidf)\n",
    "\n",
    "# the accuracy\n",
    "final_test_accuracy = accuracy_score(final_test_data['label'], final_test_pred)\n",
    "print(f'Final Test Set Accuracy: {final_test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a949e73",
   "metadata": {},
   "source": [
    "## Word N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b3dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word N-Gram Model Accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "# After exporting the above model and vectorizer to my command line script, I quickly found with some tests, that the model had overfit to the training data and struggled with short text and language with a more natural tone\n",
    "\n",
    "# Tried using word n-grams instead of character n-grams\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', max_features=10000)\n",
    "\n",
    "X_train_word_tfidf = word_vectorizer.fit_transform(X_train)\n",
    "X_test_word_tfidf = word_vectorizer.transform(X_test)\n",
    "\n",
    "naive_bayes_model_word = MultinomialNB()\n",
    "naive_bayes_model_word.fit(X_train_word_tfidf, y_train)\n",
    "y_pred_word = naive_bayes_model_word.predict(X_test_word_tfidf)\n",
    "accuracy_word = accuracy_score(y_test, y_pred_word)\n",
    "print(f'Word N-Gram Model Accuracy: {accuracy_word:.4f}')\n",
    "# Accuracy was worse, and after exporting the model, it sill was unable to generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816cf7ef",
   "metadata": {},
   "source": [
    "## Train on extra data for common languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd1199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Model Accuracy: 0.9172\n"
     ]
    }
   ],
   "source": [
    "# In real world scenarios, many of the languges in the dataset are very unlikely to occur. Below I will add some extra data for the most common languages to help the model generalize better.\n",
    "\n",
    "common_languages = common_languages = ['eng']\n",
    "\n",
    "# Oversample these languages by multiplying their samples in the training set\n",
    "common_lang_data = data[data['label'].isin(common_languages)]\n",
    "common_lang_data = pd.concat([common_lang_data]*2, ignore_index=True) \n",
    "\n",
    "# Combine with the original training data\n",
    "oversampled_train_data = pd.concat([data, common_lang_data], ignore_index=True)\n",
    "\n",
    "over_X_train, over_y_train = oversampled_train_data['text'], oversampled_train_data['label']\n",
    "over_vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char', max_features=10000)\n",
    "over_X_train_tfidf = over_vectorizer.fit_transform(over_X_train)\n",
    "X_test_tfidf = over_vectorizer.transform(X_test)\n",
    "naive_bayes_model_over = MultinomialNB()\n",
    "naive_bayes_model_over.fit(over_X_train_tfidf, over_y_train)\n",
    "y_pred_over = naive_bayes_model_over.predict(X_test_tfidf)\n",
    "accuracy_over = accuracy_score(y_test, y_pred_over)\n",
    "print(f'Oversampled Model Accuracy: {accuracy_over:.4f}')\n",
    "\n",
    "# Accuracy dropped signigicantly, but it gets the short common phrases correct that the previous model missed.\n",
    "# Below I will create an ensemble model that uses both models and picks the prediction from the model that is more confident in its prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f951e",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Results:\n",
      "'Hello, how are you today?' -> Cornish (original model, conf: 0.114)\n",
      "'What's the weather like?' -> English (enhanced model, conf: 0.956)\n",
      "'Thank you very much' -> English (enhanced model, conf: 0.404)\n",
      "'Nice to meet you' -> English (enhanced model, conf: 0.404)\n",
      "'Have a great day' -> English (enhanced model, conf: 0.522)\n",
      "'How was your weekend?' -> Cornish (original model, conf: 0.125)\n",
      "'I'm doing well, thanks' -> English (enhanced model, conf: 0.538)\n",
      "'See you later' -> Wolof (original model, conf: 0.092)\n",
      "'Good morning everyone' -> English (enhanced model, conf: 0.653)\n",
      "'Can you help me please?' -> English (enhanced model, conf: 0.432)\n",
      "'I love this song' -> English (enhanced model, conf: 0.766)\n",
      "'What time is it?' -> English (enhanced model, conf: 0.730)\n",
      "'Where are you from?' -> English (enhanced model, conf: 0.606)\n",
      "'How much does this cost?' -> English (enhanced model, conf: 0.811)\n",
      "'I'm hungry, let's eat' -> Narom (original model, conf: 0.093)\n",
      "'Excuse me' -> Galician (original model, conf: 0.043)\n",
      "'You're welcome' -> Limburgan (original model, conf: 0.063)\n",
      "'I don't understand' -> Vlaams (original model, conf: 0.075)\n",
      "'Could you repeat that?' -> English (enhanced model, conf: 0.792)\n",
      "'What's your name?' -> English (enhanced model, conf: 0.463)\n",
      "'Hola, ¿cómo estás?' -> Extremaduran (original model, conf: 0.084)\n",
      "'¿Qué tal el tiempo?' -> Extremaduran (original model, conf: 0.171)\n",
      "'Muchas gracias' -> Extremaduran (original model, conf: 0.098)\n",
      "'Mucho gusto' -> Scottish Gaelic (original model, conf: 0.046)\n",
      "'Que tengas buen día' -> Extremaduran (original model, conf: 0.107)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Galician (original model, conf: 0.056)\n",
      "'Estoy bien, gracias' -> Spanish (original model, conf: 0.059)\n",
      "'Hasta luego' -> Extremaduran (original model, conf: 0.031)\n",
      "'Buenos días a todos' -> Galician (original model, conf: 0.216)\n",
      "'¿Me puedes ayudar?' -> Asturian (original model, conf: 0.062)\n",
      "'Me encanta esta canción' -> Aragonese (original model, conf: 0.184)\n",
      "'¿Qué hora es?' -> Arpitan (original model, conf: 0.067)\n",
      "'¿De dónde eres?' -> Spanish (original model, conf: 0.073)\n",
      "'¿Cuánto cuesta esto?' -> Spanish (original model, conf: 0.104)\n",
      "'Tengo hambre, vamos a comer' -> Portuguese (original model, conf: 0.082)\n",
      "'Disculpe' -> Friulian (original model, conf: 0.056)\n",
      "'De nada' -> Chavacano (original model, conf: 0.053)\n",
      "'No entiendo' -> Spanish (original model, conf: 0.083)\n",
      "'¿Puedes repetir eso?' -> Asturian (original model, conf: 0.070)\n",
      "'¿Cómo te llamas?' -> Asturian (original model, conf: 0.061)\n",
      "'Bonjour, comment allez-vous?' -> French (original model, conf: 0.138)\n",
      "'Quel temps fait-il?' -> Occitan (original model, conf: 0.069)\n",
      "'Merci beaucoup' -> French (original model, conf: 0.033)\n",
      "'Enchanté' -> Narom (original model, conf: 0.062)\n",
      "'Passez une bonne journée' -> French (original model, conf: 0.157)\n",
      "'Comment s'est passé votre weekend?' -> French (original model, conf: 0.108)\n",
      "'Je vais bien, merci' -> West Low German (original model, conf: 0.058)\n",
      "'À bientôt' -> French (original model, conf: 0.045)\n",
      "'Bonjour tout le monde' -> French (original model, conf: 0.143)\n",
      "'Pouvez-vous m'aider?' -> Narom (original model, conf: 0.090)\n",
      "'J'adore cette chanson' -> Tarantino dialect (original model, conf: 0.168)\n",
      "'Quelle heure est-il?' -> French (original model, conf: 0.179)\n",
      "'D'où venez-vous?' -> Breton (original model, conf: 0.262)\n",
      "'Combien ça coûte?' -> Ligurian (original model, conf: 0.087)\n",
      "'J'ai faim, allons manger' -> Occitan (original model, conf: 0.042)\n",
      "'Excusez-moi' -> Xhosa (original model, conf: 0.034)\n",
      "'De rien' -> West Low German (original model, conf: 0.052)\n",
      "'Je ne comprends pas' -> French (original model, conf: 0.058)\n",
      "'Pouvez-vous répéter?' -> French (original model, conf: 0.211)\n",
      "'Comment vous appelez-vous?' -> French (original model, conf: 0.085)\n",
      "'Hallo, wie geht es dir?' -> Pennsylvania German (original model, conf: 0.115)\n",
      "'Wie ist das Wetter?' -> German (original model, conf: 0.100)\n",
      "'Vielen Dank' -> Livvi-Karelian (original model, conf: 0.074)\n",
      "'Freut mich' -> German (original model, conf: 0.053)\n",
      "'Schönen Tag noch' -> Ripuarisch (original model, conf: 0.106)\n",
      "'Wie war dein Wochenende?' -> German (original model, conf: 0.186)\n",
      "'Mir geht es gut, danke' -> Luxembourgish (original model, conf: 0.061)\n",
      "'Bis später' -> Saterfriesisch (original model, conf: 0.121)\n",
      "'Guten Morgen alle' -> German (original model, conf: 0.060)\n",
      "'Kannst du mir helfen?' -> Icelandic (original model, conf: 0.073)\n",
      "'Ich liebe dieses Lied' -> German (original model, conf: 0.127)\n",
      "'Wie spät ist es?' -> Saterfriesisch (original model, conf: 0.262)\n",
      "'Woher kommst du?' -> Ripuarisch (original model, conf: 0.067)\n",
      "'Wie viel kostet das?' -> Afrikaans (original model, conf: 0.096)\n",
      "'Ich habe Hunger, lass uns essen' -> Pennsylvania German (original model, conf: 0.108)\n",
      "'Entschuldigung' -> German (original model, conf: 0.126)\n",
      "'Bitte schön' -> Ripuarisch (original model, conf: 0.198)\n",
      "'Ich verstehe nicht' -> German (original model, conf: 0.183)\n",
      "'Können Sie das wiederholen?' -> German (original model, conf: 0.158)\n",
      "'Wie heißen Sie?' -> German (original model, conf: 0.134)\n",
      "'Привет, как дела?' -> Eastern Mari (original model, conf: 0.162)\n",
      "'Какая погода?' -> Russian (original model, conf: 0.308)\n",
      "'Большое спасибо' -> Russian (original model, conf: 0.146)\n",
      "'Приятно познакомиться' -> Russian (original model, conf: 0.286)\n",
      "'Хорошего дня' -> Ukrainian (original model, conf: 0.223)\n",
      "'Как прошли выходные?' -> Rusyn (original model, conf: 0.311)\n",
      "'У меня всё хорошо, спасибо' -> Ukrainian (original model, conf: 0.185)\n",
      "'Увидимся позже' -> Ukrainian (original model, conf: 0.281)\n",
      "'Доброе утро всем' -> Russian (original model, conf: 0.193)\n",
      "'Можете мне помочь?' -> Russian (original model, conf: 0.177)\n",
      "'Мне нравится эта песня' -> Russian (original model, conf: 0.215)\n",
      "'Который час?' -> Rusyn (original model, conf: 0.278)\n",
      "'Откуда вы?' -> Komi-Permyak (original model, conf: 0.124)\n",
      "'Сколько это стоит?' -> Russian (original model, conf: 0.247)\n",
      "'Я голоден, давайте поедим' -> Bulgarian (original model, conf: 0.256)\n",
      "'Извините' -> Bulgarian (original model, conf: 0.242)\n",
      "'Пожалуйста' -> Ukrainian (original model, conf: 0.097)\n",
      "'Я не понимаю' -> Russian (original model, conf: 0.219)\n",
      "'Можете повторить?' -> Russian (original model, conf: 0.202)\n",
      "'Как вас зовут?' -> Ukrainian (original model, conf: 0.099)\n",
      "Original results:\n",
      "'Hello, how are you today?' -> Cornish (original model)\n",
      "'What's the weather like?' -> English (original model)\n",
      "'Thank you very much' -> Shona (original model)\n",
      "'Nice to meet you' -> Scots (original model)\n",
      "'Have a great day' -> Breton (original model)\n",
      "'How was your weekend?' -> Cornish (original model)\n",
      "'I'm doing well, thanks' -> English (original model)\n",
      "'See you later' -> Wolof (original model)\n",
      "'Good morning everyone' -> English (original model)\n",
      "'Can you help me please?' -> Picard (original model)\n",
      "'I love this song' -> English (original model)\n",
      "'What time is it?' -> Scots (original model)\n",
      "'Where are you from?' -> English (original model)\n",
      "'How much does this cost?' -> English (original model)\n",
      "'I'm hungry, let's eat' -> Narom (original model)\n",
      "'Excuse me' -> Galician (original model)\n",
      "'You're welcome' -> Limburgan (original model)\n",
      "'I don't understand' -> Vlaams (original model)\n",
      "'Could you repeat that?' -> English (original model)\n",
      "'What's your name?' -> English (original model)\n",
      "'Hola, ¿cómo estás?' -> Extremaduran (original model)\n",
      "'¿Qué tal el tiempo?' -> Extremaduran (original model)\n",
      "'Muchas gracias' -> Extremaduran (original model)\n",
      "'Mucho gusto' -> Scottish Gaelic (original model)\n",
      "'Que tengas buen día' -> Extremaduran (original model)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Galician (original model)\n",
      "'Estoy bien, gracias' -> Spanish (original model)\n",
      "'Hasta luego' -> Extremaduran (original model)\n",
      "'Buenos días a todos' -> Galician (original model)\n",
      "'¿Me puedes ayudar?' -> Asturian (original model)\n",
      "'Me encanta esta canción' -> Aragonese (original model)\n",
      "'¿Qué hora es?' -> Arpitan (original model)\n",
      "'¿De dónde eres?' -> Spanish (original model)\n",
      "'¿Cuánto cuesta esto?' -> Spanish (original model)\n",
      "'Tengo hambre, vamos a comer' -> Portuguese (original model)\n",
      "'Disculpe' -> Friulian (original model)\n",
      "'De nada' -> Chavacano (original model)\n",
      "'No entiendo' -> Spanish (original model)\n",
      "'¿Puedes repetir eso?' -> Asturian (original model)\n",
      "'¿Cómo te llamas?' -> Asturian (original model)\n",
      "'Bonjour, comment allez-vous?' -> French (original model)\n",
      "'Quel temps fait-il?' -> Occitan (original model)\n",
      "'Merci beaucoup' -> French (original model)\n",
      "'Enchanté' -> Narom (original model)\n",
      "'Passez une bonne journée' -> French (original model)\n",
      "'Comment s'est passé votre weekend?' -> French (original model)\n",
      "'Je vais bien, merci' -> West Low German (original model)\n",
      "'À bientôt' -> French (original model)\n",
      "'Bonjour tout le monde' -> French (original model)\n",
      "'Pouvez-vous m'aider?' -> Narom (original model)\n",
      "'J'adore cette chanson' -> Tarantino dialect (original model)\n",
      "'Quelle heure est-il?' -> French (original model)\n",
      "'D'où venez-vous?' -> Breton (original model)\n",
      "'Combien ça coûte?' -> Ligurian (original model)\n",
      "'J'ai faim, allons manger' -> Occitan (original model)\n",
      "'Excusez-moi' -> Xhosa (original model)\n",
      "'De rien' -> West Low German (original model)\n",
      "'Je ne comprends pas' -> French (original model)\n",
      "'Pouvez-vous répéter?' -> French (original model)\n",
      "'Comment vous appelez-vous?' -> French (original model)\n",
      "'Hallo, wie geht es dir?' -> Pennsylvania German (original model)\n",
      "'Wie ist das Wetter?' -> German (original model)\n",
      "'Vielen Dank' -> Livvi-Karelian (original model)\n",
      "'Freut mich' -> German (original model)\n",
      "'Schönen Tag noch' -> Ripuarisch (original model)\n",
      "'Wie war dein Wochenende?' -> German (original model)\n",
      "'Mir geht es gut, danke' -> Luxembourgish (original model)\n",
      "'Bis später' -> Saterfriesisch (original model)\n",
      "'Guten Morgen alle' -> German (original model)\n",
      "'Kannst du mir helfen?' -> Icelandic (original model)\n",
      "'Ich liebe dieses Lied' -> German (original model)\n",
      "'Wie spät ist es?' -> Saterfriesisch (original model)\n",
      "'Woher kommst du?' -> Ripuarisch (original model)\n",
      "'Wie viel kostet das?' -> Afrikaans (original model)\n",
      "'Ich habe Hunger, lass uns essen' -> Pennsylvania German (original model)\n",
      "'Entschuldigung' -> German (original model)\n",
      "'Bitte schön' -> Ripuarisch (original model)\n",
      "'Ich verstehe nicht' -> German (original model)\n",
      "'Können Sie das wiederholen?' -> German (original model)\n",
      "'Wie heißen Sie?' -> German (original model)\n",
      "'Привет, как дела?' -> Eastern Mari (original model)\n",
      "'Какая погода?' -> Russian (original model)\n",
      "'Большое спасибо' -> Russian (original model)\n",
      "'Приятно познакомиться' -> Russian (original model)\n",
      "'Хорошего дня' -> Ukrainian (original model)\n",
      "'Как прошли выходные?' -> Rusyn (original model)\n",
      "'У меня всё хорошо, спасибо' -> Ukrainian (original model)\n",
      "'Увидимся позже' -> Ukrainian (original model)\n",
      "'Доброе утро всем' -> Russian (original model)\n",
      "'Можете мне помочь?' -> Russian (original model)\n",
      "'Мне нравится эта песня' -> Russian (original model)\n",
      "'Который час?' -> Rusyn (original model)\n",
      "'Откуда вы?' -> Komi-Permyak (original model)\n",
      "'Сколько это стоит?' -> Russian (original model)\n",
      "'Я голоден, давайте поедим' -> Bulgarian (original model)\n",
      "'Извините' -> Bulgarian (original model)\n",
      "'Пожалуйста' -> Ukrainian (original model)\n",
      "'Я не понимаю' -> Russian (original model)\n",
      "'Можете повторить?' -> Russian (original model)\n",
      "'Как вас зовут?' -> Ukrainian (original model)\n",
      "Oversampled Results:\n",
      "'Hello, how are you today?' -> English (Oversampled model)\n",
      "'What's the weather like?' -> English (Oversampled model)\n",
      "'Thank you very much' -> English (Oversampled model)\n",
      "'Nice to meet you' -> English (Oversampled model)\n",
      "'Have a great day' -> English (Oversampled model)\n",
      "'How was your weekend?' -> English (Oversampled model)\n",
      "'I'm doing well, thanks' -> English (Oversampled model)\n",
      "'See you later' -> English (Oversampled model)\n",
      "'Good morning everyone' -> English (Oversampled model)\n",
      "'Can you help me please?' -> English (Oversampled model)\n",
      "'I love this song' -> English (Oversampled model)\n",
      "'What time is it?' -> English (Oversampled model)\n",
      "'Where are you from?' -> English (Oversampled model)\n",
      "'How much does this cost?' -> English (Oversampled model)\n",
      "'I'm hungry, let's eat' -> English (Oversampled model)\n",
      "'Excuse me' -> English (Oversampled model)\n",
      "'You're welcome' -> English (Oversampled model)\n",
      "'I don't understand' -> English (Oversampled model)\n",
      "'Could you repeat that?' -> English (Oversampled model)\n",
      "'What's your name?' -> English (Oversampled model)\n",
      "'Hola, ¿cómo estás?' -> Extremaduran (Oversampled model)\n",
      "'¿Qué tal el tiempo?' -> Extremaduran (Oversampled model)\n",
      "'Muchas gracias' -> English (Oversampled model)\n",
      "'Mucho gusto' -> English (Oversampled model)\n",
      "'Que tengas buen día' -> Aragonese (Oversampled model)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Galician (Oversampled model)\n",
      "'Estoy bien, gracias' -> English (Oversampled model)\n",
      "'Hasta luego' -> English (Oversampled model)\n",
      "'Buenos días a todos' -> Galician (Oversampled model)\n",
      "'¿Me puedes ayudar?' -> Asturian (Oversampled model)\n",
      "'Me encanta esta canción' -> Aragonese (Oversampled model)\n",
      "'¿Qué hora es?' -> Arpitan (Oversampled model)\n",
      "'¿De dónde eres?' -> Spanish (Oversampled model)\n",
      "'¿Cuánto cuesta esto?' -> Spanish (Oversampled model)\n",
      "'Tengo hambre, vamos a comer' -> English (Oversampled model)\n",
      "'Disculpe' -> Friulian (Oversampled model)\n",
      "'De nada' -> Chavacano (Oversampled model)\n",
      "'No entiendo' -> Ladino (Oversampled model)\n",
      "'¿Puedes repetir eso?' -> English (Oversampled model)\n",
      "'¿Cómo te llamas?' -> Asturian (Oversampled model)\n",
      "'Bonjour, comment allez-vous?' -> English (Oversampled model)\n",
      "'Quel temps fait-il?' -> English (Oversampled model)\n",
      "'Merci beaucoup' -> English (Oversampled model)\n",
      "'Enchanté' -> Narom (Oversampled model)\n",
      "'Passez une bonne journée' -> French (Oversampled model)\n",
      "'Comment s'est passé votre weekend?' -> English (Oversampled model)\n",
      "'Je vais bien, merci' -> West Low German (Oversampled model)\n",
      "'À bientôt' -> French (Oversampled model)\n",
      "'Bonjour tout le monde' -> English (Oversampled model)\n",
      "'Pouvez-vous m'aider?' -> Narom (Oversampled model)\n",
      "'J'adore cette chanson' -> English (Oversampled model)\n",
      "'Quelle heure est-il?' -> French (Oversampled model)\n",
      "'D'où venez-vous?' -> Breton (Oversampled model)\n",
      "'Combien ça coûte?' -> Ligurian (Oversampled model)\n",
      "'J'ai faim, allons manger' -> English (Oversampled model)\n",
      "'Excusez-moi' -> English (Oversampled model)\n",
      "'De rien' -> English (Oversampled model)\n",
      "'Je ne comprends pas' -> English (Oversampled model)\n",
      "'Pouvez-vous répéter?' -> French (Oversampled model)\n",
      "'Comment vous appelez-vous?' -> English (Oversampled model)\n",
      "'Hallo, wie geht es dir?' -> English (Oversampled model)\n",
      "'Wie ist das Wetter?' -> English (Oversampled model)\n",
      "'Vielen Dank' -> Livvi-Karelian (Oversampled model)\n",
      "'Freut mich' -> English (Oversampled model)\n",
      "'Schönen Tag noch' -> Low German (Oversampled model)\n",
      "'Wie war dein Wochenende?' -> German (Oversampled model)\n",
      "'Mir geht es gut, danke' -> English (Oversampled model)\n",
      "'Bis später' -> Saterfriesisch (Oversampled model)\n",
      "'Guten Morgen alle' -> English (Oversampled model)\n",
      "'Kannst du mir helfen?' -> Icelandic (Oversampled model)\n",
      "'Ich liebe dieses Lied' -> English (Oversampled model)\n",
      "'Wie spät ist es?' -> Saterfriesisch (Oversampled model)\n",
      "'Woher kommst du?' -> English (Oversampled model)\n",
      "'Wie viel kostet das?' -> Afrikaans (Oversampled model)\n",
      "'Ich habe Hunger, lass uns essen' -> English (Oversampled model)\n",
      "'Entschuldigung' -> German (Oversampled model)\n",
      "'Bitte schön' -> Ripuarisch (Oversampled model)\n",
      "'Ich verstehe nicht' -> German (Oversampled model)\n",
      "'Können Sie das wiederholen?' -> German (Oversampled model)\n",
      "'Wie heißen Sie?' -> German (Oversampled model)\n",
      "'Привет, как дела?' -> Eastern Mari (Oversampled model)\n",
      "'Какая погода?' -> Russian (Oversampled model)\n",
      "'Большое спасибо' -> Russian (Oversampled model)\n",
      "'Приятно познакомиться' -> Russian (Oversampled model)\n",
      "'Хорошего дня' -> Russian (Oversampled model)\n",
      "'Как прошли выходные?' -> Rusyn (Oversampled model)\n",
      "'У меня всё хорошо, спасибо' -> Rusyn (Oversampled model)\n",
      "'Увидимся позже' -> Ukrainian (Oversampled model)\n",
      "'Доброе утро всем' -> Russian (Oversampled model)\n",
      "'Можете мне помочь?' -> Eastern Mari (Oversampled model)\n",
      "'Мне нравится эта песня' -> Russian (Oversampled model)\n",
      "'Который час?' -> Rusyn (Oversampled model)\n",
      "'Откуда вы?' -> Komi-Permyak (Oversampled model)\n",
      "'Сколько это стоит?' -> Russian (Oversampled model)\n",
      "'Я голоден, давайте поедим' -> Bulgarian (Oversampled model)\n",
      "'Извините' -> Bulgarian (Oversampled model)\n",
      "'Пожалуйста' -> Ukrainian (Oversampled model)\n",
      "'Я не понимаю' -> Russian (Oversampled model)\n",
      "'Можете повторить?' -> Russian (Oversampled model)\n",
      "'Как вас зовут?' -> Rusyn (Oversampled model)\n",
      "Word N-Gram Results:\n",
      "'Hello, how are you today?' -> Avar (Word N-gram model)\n",
      "'What's the weather like?' -> English (Word N-gram model)\n",
      "'Thank you very much' -> Avar (Word N-gram model)\n",
      "'Nice to meet you' -> Avar (Word N-gram model)\n",
      "'Have a great day' -> English (Word N-gram model)\n",
      "'How was your weekend?' -> English (Word N-gram model)\n",
      "'I'm doing well, thanks' -> Luxembourgish (Word N-gram model)\n",
      "'See you later' -> Avar (Word N-gram model)\n",
      "'Good morning everyone' -> West Low German (Word N-gram model)\n",
      "'Can you help me please?' -> Avar (Word N-gram model)\n",
      "'I love this song' -> English (Word N-gram model)\n",
      "'What time is it?' -> English (Word N-gram model)\n",
      "'Where are you from?' -> English (Word N-gram model)\n",
      "'How much does this cost?' -> English (Word N-gram model)\n",
      "'I'm hungry, let's eat' -> Czech (Word N-gram model)\n",
      "'Excuse me' -> Fiji Hindi (Word N-gram model)\n",
      "'You're welcome' -> Avar (Word N-gram model)\n",
      "'I don't understand' -> Irish (Word N-gram model)\n",
      "'Could you repeat that?' -> Avar (Word N-gram model)\n",
      "'What's your name?' -> Avar (Word N-gram model)\n",
      "'Hola, ¿cómo estás?' -> Polish (Word N-gram model)\n",
      "'¿Qué tal el tiempo?' -> Classical Nahuatl (Word N-gram model)\n",
      "'Muchas gracias' -> Polish (Word N-gram model)\n",
      "'Mucho gusto' -> Polish (Word N-gram model)\n",
      "'Que tengas buen día' -> Galician (Word N-gram model)\n",
      "'¿Cómo estuvo tu fin de semana?' -> Aromanian (Word N-gram model)\n",
      "'Estoy bien, gracias' -> Asturian (Word N-gram model)\n",
      "'Hasta luego' -> Spanish (Word N-gram model)\n",
      "'Buenos días a todos' -> Guarani (Word N-gram model)\n",
      "'¿Me puedes ayudar?' -> Fiji Hindi (Word N-gram model)\n",
      "'Me encanta esta canción' -> Fiji Hindi (Word N-gram model)\n",
      "'¿Qué hora es?' -> Classical Nahuatl (Word N-gram model)\n",
      "'¿De dónde eres?' -> Mirandese (Word N-gram model)\n",
      "'¿Cuánto cuesta esto?' -> Dimli (Word N-gram model)\n",
      "'Tengo hambre, vamos a comer' -> Polish (Word N-gram model)\n",
      "'Disculpe' -> Polish (Word N-gram model)\n",
      "'De nada' -> Mirandese (Word N-gram model)\n",
      "'No entiendo' -> Latvian (Word N-gram model)\n",
      "'¿Puedes repetir eso?' -> Classical Nahuatl (Word N-gram model)\n",
      "'¿Cómo te llamas?' -> Maori (Word N-gram model)\n",
      "'Bonjour, comment allez-vous?' -> Polish (Word N-gram model)\n",
      "'Quel temps fait-il?' -> French (Word N-gram model)\n",
      "'Merci beaucoup' -> Polish (Word N-gram model)\n",
      "'Enchanté' -> Polish (Word N-gram model)\n",
      "'Passez une bonne journée' -> French (Word N-gram model)\n",
      "'Comment s'est passé votre weekend?' -> Latin (Word N-gram model)\n",
      "'Je vais bien, merci' -> Slovene (Word N-gram model)\n",
      "'À bientôt' -> Polish (Word N-gram model)\n",
      "'Bonjour tout le monde' -> French (Word N-gram model)\n",
      "'Pouvez-vous m'aider?' -> Polish (Word N-gram model)\n",
      "'J'adore cette chanson' -> French (Word N-gram model)\n",
      "'Quelle heure est-il?' -> French (Word N-gram model)\n",
      "'D'où venez-vous?' -> Polish (Word N-gram model)\n",
      "'Combien ça coûte?' -> Polish (Word N-gram model)\n",
      "'J'ai faim, allons manger' -> Maori (Word N-gram model)\n",
      "'Excusez-moi' -> Galician (Word N-gram model)\n",
      "'De rien' -> Mirandese (Word N-gram model)\n",
      "'Je ne comprends pas' -> Bosnian (Word N-gram model)\n",
      "'Pouvez-vous répéter?' -> Polish (Word N-gram model)\n",
      "'Comment vous appelez-vous?' -> Polish (Word N-gram model)\n",
      "'Hallo, wie geht es dir?' -> Pennsylvania German (Word N-gram model)\n",
      "'Wie ist das Wetter?' -> Pampanga (Word N-gram model)\n",
      "'Vielen Dank' -> Polish (Word N-gram model)\n",
      "'Freut mich' -> Polish (Word N-gram model)\n",
      "'Schönen Tag noch' -> Ripuarisch (Word N-gram model)\n",
      "'Wie war dein Wochenende?' -> German (Word N-gram model)\n",
      "'Mir geht es gut, danke' -> Pennsylvania German (Word N-gram model)\n",
      "'Bis später' -> German (Word N-gram model)\n",
      "'Guten Morgen alle' -> Danish (Word N-gram model)\n",
      "'Kannst du mir helfen?' -> Karakalpak (Word N-gram model)\n",
      "'Ich liebe dieses Lied' -> Slovak (Word N-gram model)\n",
      "'Wie spät ist es?' -> Pampanga (Word N-gram model)\n",
      "'Woher kommst du?' -> French (Word N-gram model)\n",
      "'Wie viel kostet das?' -> Pampanga (Word N-gram model)\n",
      "'Ich habe Hunger, lass uns essen' -> Pennsylvania German (Word N-gram model)\n",
      "'Entschuldigung' -> Polish (Word N-gram model)\n",
      "'Bitte schön' -> Polish (Word N-gram model)\n",
      "'Ich verstehe nicht' -> Pampanga (Word N-gram model)\n",
      "'Können Sie das wiederholen?' -> Pampanga (Word N-gram model)\n",
      "'Wie heißen Sie?' -> Pennsylvania German (Word N-gram model)\n",
      "'Привет, как дела?' -> Russian (Word N-gram model)\n",
      "'Какая погода?' -> Polish (Word N-gram model)\n",
      "'Большое спасибо' -> Polish (Word N-gram model)\n",
      "'Приятно познакомиться' -> Polish (Word N-gram model)\n",
      "'Хорошего дня' -> Polish (Word N-gram model)\n",
      "'Как прошли выходные?' -> Russian (Word N-gram model)\n",
      "'У меня всё хорошо, спасибо' -> Polish (Word N-gram model)\n",
      "'Увидимся позже' -> Polish (Word N-gram model)\n",
      "'Доброе утро всем' -> Polish (Word N-gram model)\n",
      "'Можете мне помочь?' -> Polish (Word N-gram model)\n",
      "'Мне нравится эта песня' -> Polish (Word N-gram model)\n",
      "'Который час?' -> Ukrainian (Word N-gram model)\n",
      "'Откуда вы?' -> Polish (Word N-gram model)\n",
      "'Сколько это стоит?' -> Polish (Word N-gram model)\n",
      "'Я голоден, давайте поедим' -> Polish (Word N-gram model)\n",
      "'Извините' -> Polish (Word N-gram model)\n",
      "'Пожалуйста' -> Polish (Word N-gram model)\n",
      "'Я не понимаю' -> Russian (Word N-gram model)\n",
      "'Можете повторить?' -> Polish (Word N-gram model)\n",
      "'Как вас зовут?' -> Russian (Word N-gram model)\n"
     ]
    }
   ],
   "source": [
    "def ensemble_predict(text):\n",
    "    orig_features = vectorizer.transform([text])\n",
    "    orig_proba = naive_bayes_model.predict_proba(orig_features)[0]\n",
    "    orig_pred = naive_bayes_model.predict(orig_features)[0]\n",
    "    orig_confidence = orig_proba.max()\n",
    "    \n",
    "    over_features = over_vectorizer.transform([text])\n",
    "    over_proba = naive_bayes_model_over.predict_proba(over_features)[0]\n",
    "    over_pred = naive_bayes_model_over.predict(over_features)[0]\n",
    "    over_confidence = over_proba.max()\n",
    "    \n",
    "    if over_confidence > orig_confidence and over_confidence > .5:\n",
    "        return over_pred, \"overtrained\", over_confidence\n",
    "    else:\n",
    "        return orig_pred, \"original\", orig_confidence\n",
    "\n",
    "# Some random conversational phrases compiled into json using ai\n",
    "with open('common_phrases.json', 'r', encoding='utf-8') as f:\n",
    "    phrases_data = json.load(f)\n",
    "\n",
    "test_phrases = []\n",
    "for lang_code, phrases in phrases_data.items():\n",
    "    test_phrases.extend(phrases)\n",
    "\n",
    "print(\"Ensemble Results:\")\n",
    "for phrase in test_phrases:\n",
    "    pred, model_used, conf = ensemble_predict(phrase)\n",
    "    lang_name = label_map.get(pred, pred)\n",
    "    print(f\"'{phrase}' -> {lang_name} ({model_used} model, conf: {conf:.3f})\")\n",
    "\n",
    "print(\"Original results:\")\n",
    "for phrase in test_phrases:\n",
    "    orig_features = vectorizer.transform([phrase])\n",
    "    orig_pred = naive_bayes_model.predict(orig_features)[0]\n",
    "    lang_name = label_map.get(orig_pred, orig_pred)\n",
    "    print(f\"'{phrase}' -> {lang_name} (original model)\")\n",
    "\n",
    "print(\"Oversampled Results:\")\n",
    "for phrase in test_phrases:\n",
    "    over_features = over_vectorizer.transform([phrase])\n",
    "    over_pred = naive_bayes_model_over.predict(over_features)[0]\n",
    "    lang_name = label_map.get(over_pred, over_pred)\n",
    "    print(f\"'{phrase}' -> {lang_name} (Oversampled model)\")\n",
    "\n",
    "print(\"Word N-Gram Results:\")\n",
    "for phrase in test_phrases:\n",
    "   word_features = word_vectorizer.transform([phrase])\n",
    "   word_pred = naive_bayes_model_word.predict(word_features)[0]\n",
    "   lang_name = label_map.get(word_pred, word_pred)\n",
    "   print(f\"'{phrase}' -> {lang_name} (Word N-gram model)\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83eb8768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Accuracies:\n",
      "Original Model: 0.9220\n",
      "Enhanced Model: 0.9172\n",
      "Ensemble Model: 0.9174\n"
     ]
    }
   ],
   "source": [
    "# Test the ensemble on the entire wiki test set\n",
    "ensemble_predictions = []\n",
    "for text in X_test:\n",
    "    pred, _, _ = ensemble_predict(text)\n",
    "    ensemble_predictions.append(pred)\n",
    "\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(f\"\\nTest Set Accuracies:\")\n",
    "print(f\"Original Model: {accuracy:.4f}\")\n",
    "print(f\"Enhanced Model: {accuracy_over:.4f}\") \n",
    "print(f\"Ensemble Model: {ensemble_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df0356",
   "metadata": {},
   "source": [
    "## Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd3888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Export the model and vectorizer using joblib\n",
    "joblib.dump(naive_bayes_model, 'language_detection_model.joblib')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
